{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d56c0a-b003-426a-b344-d79e7f04fdf2",
   "metadata": {},
   "source": [
    "!pip install pandas, !pip install openpyxl, !pip install adjustText, !pip install statsmodels, pip install seaborn, !pip install linearmodels\n",
    "!pip install python-docx\n",
    "!pip install linearmodels --upgrade\n",
    "!pip install arch --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53bcb3c-2278-42d0-a276-2d35ed09b67b",
   "metadata": {},
   "source": [
    "# 1. IMPORT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638b320-f58c-4e9b-9331-34e24c0240c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file into a DataFrame\n",
    "file_path = \"./Original_Data/2018-v272-05072025-EU MRV Publication of information.xlsx\"\n",
    "data_18 = pd.read_excel(file_path, header=2)\n",
    "\n",
    "file_path = \"./Original_Data/2019-v227-28052025-EU MRV Publication of information.xlsx\"\n",
    "data_19 = pd.read_excel(file_path, header=2)\n",
    "\n",
    "file_path = \"./Original_Data/2020-v207-23082025-EU MRV Publication of information.xlsx\"\n",
    "data_20 = pd.read_excel(file_path, header=2)\n",
    "\n",
    "file_path = \"./Original_Data/2021-v214-30042025-EU MRV Publication of information.xlsx\"\n",
    "data_21 = pd.read_excel(file_path, header=2)\n",
    "\n",
    "file_path = \"./Original_Data/2022-v238-01082025-EU MRV Publication of information.xlsx\"\n",
    "data_22 = pd.read_excel(file_path, header=2)\n",
    "\n",
    "file_path = \"./Original_Data/2023-v70-04092025-EU MRV Publication of information.xlsx\"\n",
    "data_23 = pd.read_excel(file_path, header=2)\n",
    "\n",
    "file_path = \"./Original_Data/2024-v62-06092025-EU MRV Publication of information.xlsx\"\n",
    "data_24 = pd.read_excel(file_path, header=2)\n",
    "\n",
    "target_cols = [\n",
    "    \"Ship type\",\"IMO Number\", \"Name\",\"Reporting Period\",\"Technical efficiency\",\n",
    "    \"A\", \"B\", \"C\", \"D\",\n",
    "    \"Total fuel consumption [m tonnes]\",\n",
    "    \"Total CO₂ emissions [m tonnes]\",\n",
    "    \"Annual Time spent at sea [hours]\",\n",
    "    \n",
    "    \"Annual average Fuel consumption per distance [kg / n mile]\",\n",
    "    \"Annual average Fuel consumption per transport work (volume) [g / m³ · n miles]\",\n",
    "    \"Annual average Fuel consumption per transport work (mass) [g / m tonnes · n miles]\",\n",
    "    \"Annual average Fuel consumption per transport work (dwt) [g / dwt carried · n miles]\",\n",
    "    \"Annual average Fuel consumption per transport work (freight) [g / m tonnes · n miles]\",\n",
    "    \"Annual average Fuel consumption per transport work (pax) [g / pax · n miles]\",\n",
    "\n",
    "    \"Annual average CO₂ emissions per distance [kg CO₂ / n mile]\",\n",
    "    \"Annual average CO₂ emissions per transport work (volume) [g CO₂ / m³ · n miles]\",\n",
    "    \"Annual average CO₂ emissions per transport work (mass) [g CO₂ / m tonnes · n miles]\",\n",
    "    \"Annual average CO₂ emissions per transport work (dwt) [g CO₂ / dwt carried · n miles]\",\n",
    "    \"Annual average CO₂ emissions per transport work (freight) [g CO₂ / m tonnes · n miles]\",\n",
    "    \"Annual average CO₂ emissions per transport work (pax) [g CO₂ / pax · n miles]\",\n",
    "]\n",
    "\n",
    "# Put DataFrames in a dictionary\n",
    "datasets = {\n",
    "    \"2018\": data_18,\n",
    "    \"2019\": data_19,\n",
    "    \"2020\": data_20,\n",
    "    \"2021\": data_21,\n",
    "    \"2022\": data_22,\n",
    "    \"2023\": data_23,\n",
    "    \"2024\": data_24\n",
    "} \n",
    "\n",
    "# Check columns\n",
    "for year, df in datasets.items():\n",
    "    missing = [col for col in target_cols if col not in df.columns]\n",
    "    print(f\"\\nYear {year}:\")\n",
    "    if not missing:\n",
    "        print(\"✅ All target columns are present.\")\n",
    "    else:\n",
    "        print(\"⚠️ Missing columns:\")\n",
    "        for col in missing:\n",
    "            print(\"   -\", col)\n",
    "#------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e40d93-81c2-4345-80bb-35c6918a07b9",
   "metadata": {},
   "source": [
    "### 1.1 Creation of a Merged Data Matrix and Basic Proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5995e52-7ba3-4500-ac02-b84cce650e3a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Creation of one merged data frame\n",
    "data = pd.concat([data_18, data_19, data_20, data_21, data_22, data_23, data_24], \n",
    "                   ignore_index=True, sort=False)[target_cols]\n",
    "data = data.sort_values(by=\"Reporting Period\")\n",
    "\n",
    "# Safely convert to numeric, keep NaN if conversion fails\n",
    "cols_to_convert = [\n",
    "    \"Annual average Fuel consumption per distance [kg / n mile]\",\n",
    "    \"Annual average Fuel consumption per transport work (volume) [g / m³ · n miles]\",\n",
    "    \"Annual average Fuel consumption per transport work (mass) [g / m tonnes · n miles]\",\n",
    "    \"Annual average Fuel consumption per transport work (dwt) [g / dwt carried · n miles]\",\n",
    "    \"Annual average Fuel consumption per transport work (freight) [g / m tonnes · n miles]\",\n",
    "    \"Annual average Fuel consumption per transport work (pax) [g / pax · n miles]\",\n",
    "\n",
    "    \"Annual average CO₂ emissions per distance [kg CO₂ / n mile]\",\n",
    "    \"Annual average CO₂ emissions per transport work (volume) [g CO₂ / m³ · n miles]\",\n",
    "    \"Annual average CO₂ emissions per transport work (mass) [g CO₂ / m tonnes · n miles]\",\n",
    "    \"Annual average CO₂ emissions per transport work (dwt) [g CO₂ / dwt carried · n miles]\",\n",
    "    \"Annual average CO₂ emissions per transport work (freight) [g CO₂ / m tonnes · n miles]\",\n",
    "    \"Annual average CO₂ emissions per transport work (pax) [g CO₂ / pax · n miles]\",\n",
    "]\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "#----------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#Creation of Total Distance Covered column and Average Annual Speed Column\n",
    "data[\"Annual Distance per Vessel [n miles]\"] = (data[\"Total fuel consumption [m tonnes]\"] / data[\"Annual average Fuel consumption per distance [kg / n mile]\"])*1000\n",
    "data[\"Annual Distance per Vessel [n miles]\"] = data[\"Annual Distance per Vessel [n miles]\"].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "data[\"Annual Average Speed per Vessel [knots]\"] = data[\"Annual Distance per Vessel [n miles]\"] / data[\"Annual Time spent at sea [hours]\"]\n",
    "data[\"Annual Average Speed per Vessel [knots]\"] = data[\"Annual Average Speed per Vessel [knots]\"].replace([np.inf, -np.inf], np.nan)\n",
    "#-----------------------------------------------------------------------------------#\n",
    "\n",
    "#Break \"Technical Efficiency\" to two columns -> Index + Value\n",
    "def split_tech_eff(val):\n",
    "    if isinstance(val, str) and \"(\" in val and \")\" in val:\n",
    "        index = val.split(\"(\")[0].strip()                      # e.g. \"EIV\"\n",
    "        number = val.split(\"(\")[1].split()[0]                  # e.g. \"15.95\"\n",
    "        try:\n",
    "            number = float(number)\n",
    "        except:\n",
    "            number = np.nan\n",
    "        return index, number\n",
    "    else:\n",
    "        return np.nan, np.nan #because we want to be treated as floats\n",
    "\n",
    "# Apply row by row\n",
    "data[\"Technical efficiency Index\"], data[\"Technical efficiency Index Value [gCO₂/t·nm]\"] = zip(\n",
    "    *data[\"Technical efficiency\"].apply(split_tech_eff)\n",
    ")\n",
    "#--------------------------------------------------------------------------------------#\n",
    "\n",
    "#----------------MERGE PASSENGER SHIPS WITH CRUISE SHIPS & Offshore with other ship types -------------------------------#\n",
    "data[\"Ship type\"] = data[\"Ship type\"].replace(\"Other ship types (Offshore)\", \"Other ship types\")\n",
    "data[\"Ship type\"] = data[\"Ship type\"].replace(\"Passenger ship (Cruise Passenger ship)\", \"Passenger ship\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7725a2bd-6a64-44df-acc5-6f5870bd2d13",
   "metadata": {},
   "source": [
    "# 2. CLEARING THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b458ad3b-29d3-414d-bb86-2fb78b0b0654",
   "metadata": {},
   "source": [
    "## 2.1 Total Vessels - Zero Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f01c48-e40e-4b43-9d5f-9083b9792009",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#check for double entries\n",
    "duplicates = data[data.duplicated(subset=[\"IMO Number\", \"Reporting Period\"], keep=False)] \n",
    "#Since there are NO double entries count the vessels\n",
    "yearly_vessels = data.groupby(\"Reporting Period\")[\"IMO Number\"].nunique()\n",
    "#count the zero consumption entries\n",
    "yearly_zeros = ( data.groupby(\"Reporting Period\")[\"Total fuel consumption [m tonnes]\"].apply(lambda x: (x == 0).sum()) .reset_index(name=\"Zero Count\") )\n",
    "\n",
    "# Define the columns where zero should NOT exist\n",
    "cols_to_check = [\n",
    "    \"Total fuel consumption [m tonnes]\",\n",
    "    \"Total CO₂ emissions [m tonnes]\",\n",
    "    \"Annual Time spent at sea [hours]\",\n",
    "    \"Annual Distance per Vessel [n miles]\",\n",
    "]\n",
    "\n",
    "# Keep only rows where ALL those columns are non-zero\n",
    "data_no_zeros = data[(data[cols_to_check] != 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630136ce-7770-4077-8e0f-8937a9f2e79d",
   "metadata": {},
   "source": [
    "## 2.2 Remove Outliers (Beyond Zeros) - Filter by Ship Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb46bc-7941-466f-b9fd-75b06bff750d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------- Per Ship Category ----------------------------------------------------------------------------------------#\n",
    "def count_outliers_by_group_two_cols(df, cols, group_col=\"Ship type\", lower=0.025, upper=0.975, return_filtered=True):\n",
    "    \"\"\"\n",
    "    Count percentile-based outliers per group (Ship type) for two columns, \n",
    "    and optionally return filtered data (rows within both percentile ranges).\n",
    "\n",
    "    Parameters:\n",
    "        df             : pandas DataFrame\n",
    "        cols           : list of two column names\n",
    "        group_col      : column to group by (default \"Ship type\")\n",
    "        lower, upper   : percentiles for outlier detection\n",
    "        return_filtered: if True, return filtered DataFrame (rows within both ranges)\n",
    "\n",
    "    Returns:\n",
    "        outlier_counts : dict {column: {group: number of outliers}}\n",
    "        thresholds     : dict {column: {group: (low, high)}}\n",
    "        filtered_df    : DataFrame with rows within percentile ranges for both columns\n",
    "    \"\"\"\n",
    "    outlier_counts = {col: {} for col in cols}\n",
    "    thresholds = {col: {} for col in cols}\n",
    "    filtered_list = []\n",
    "\n",
    "    for group, group_df in df.groupby(group_col):\n",
    "        mask = pd.Series(True, index=group_df.index)  # start with all True\n",
    "        for col in cols:\n",
    "            low, high = group_df[col].quantile(lower), group_df[col].quantile(upper)\n",
    "            thresholds[col][group] = (low, high)\n",
    "\n",
    "            col_mask = group_df[col].between(low, high)\n",
    "            mask &= col_mask  # keep only rows within percentile for this column\n",
    "\n",
    "            outlier_counts[col][group] = (~col_mask).sum()  # count outliers for this column\n",
    "\n",
    "        if return_filtered:\n",
    "            filtered_group = group_df[mask]\n",
    "            filtered_list.append(filtered_group)\n",
    "\n",
    "    filtered_df = pd.concat(filtered_list, ignore_index=True) if return_filtered else None\n",
    "\n",
    "    return outlier_counts, thresholds, filtered_df\n",
    "#------------------END OF FUNCTION---------------------------------------------------------------#\n",
    "\n",
    "cols_to_filter_by = [\n",
    "    \"Annual average Fuel consumption per distance [kg / n mile]\",\n",
    "    \"Annual average CO₂ emissions per distance [kg CO₂ / n mile]\",\n",
    "    \"Annual Average Speed per Vessel [knots]\",\n",
    "    \n",
    "]\n",
    "\n",
    "#------------ CALL THE FUNCTION---------------------------------------------#\n",
    "outlier_counts, thresholds, filtered_data = count_outliers_by_group_two_cols(\n",
    "    data_no_zeros,\n",
    "    cols=cols_to_filter_by,\n",
    "    group_col=\"Ship type\",\n",
    "    lower=0.025,\n",
    "    upper=0.975\n",
    ")\n",
    "\n",
    "# Print outlier counts per column per ship type\n",
    "for col in cols_to_filter_by:\n",
    "    print(f\"\\nOutlier counts for column: {col}\")\n",
    "    for ship, count in outlier_counts[col].items():\n",
    "        print(f\"{ship}: {count} outliers\")\n",
    "\n",
    "# Print thresholds per column per ship type\n",
    "print(\"\\nThresholds per column per ship type:\")\n",
    "for col in cols_to_filter_by:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    for ship, (low, high) in thresholds[col].items():\n",
    "        print(f\"{ship}: {low:.2f} - {high:.2f}\")\n",
    "\n",
    "print(\"\\nFiltered data rows:\", len(filtered_data))\n",
    "print(\"\\nNO zero data rows:\", len(data_no_zeros))\n",
    "print(\"\\nInitial data rows:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ed249-eb1b-47f5-b289-0d1e62d804cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816d33d-a85c-433b-ab62-6c029294c814",
   "metadata": {},
   "source": [
    "# 3. Basic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4406d4-4f79-4209-868b-e8baa4b6729c",
   "metadata": {},
   "source": [
    "## 3.1 Total Reports - Valid and NOT Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a7f44-ee45-4230-9e35-07fbf38fee9b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Data preparation ---\n",
    "# 1. Total vessels per year (original)\n",
    "yearly_vessels = data.groupby(\"Reporting Period\")[\"IMO Number\"].nunique()\n",
    "\n",
    "# 2. Total vessels per year after outlier filtering\n",
    "filtered_vessels = filtered_data.groupby(\"Reporting Period\")[\"IMO Number\"].nunique()\n",
    "\n",
    "# 3. Zeros per year as a Series\n",
    "yearly_zeros = (\n",
    "    data.groupby(\"Reporting Period\")[\"Total fuel consumption [m tonnes]\"]\n",
    "    .apply(lambda x: (x == 0).sum())\n",
    ")\n",
    "yearly_zeros.name = \"Zero Count\"\n",
    "\n",
    "# 4. Loss due to zeros\n",
    "vessels_after_zeros = yearly_vessels - yearly_zeros\n",
    "\n",
    "# 5. Loss due to outliers\n",
    "vessels_after_outliers = filtered_vessels\n",
    "outliers_only = vessels_after_zeros - vessels_after_outliers\n",
    "\n",
    "# 6. Combine into one summary table\n",
    "summary_ = pd.DataFrame({\n",
    "    \"Total Reported Vessels\": yearly_vessels,\n",
    "    \"Zeros Removed\": yearly_zeros,\n",
    "    \"Outliers Removed\": outliers_only,\n",
    "    \"Final Valid Vessels\": filtered_vessels\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "# --- Plot setup ---\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"   # set font globally\n",
    "plt.rcParams[\"axes.titlesize\"] = 15\n",
    "plt.rcParams[\"axes.labelsize\"] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 11\n",
    "plt.rcParams[\"ytick.labelsize\"] = 11\n",
    "\n",
    "# Data for plotting\n",
    "line_df = summary_[[\"Total Reported Vessels\", \"Final Valid Vessels\", \n",
    "                    \"Zeros Removed\", \"Outliers Removed\"]]\n",
    "\n",
    "# Create line plot\n",
    "FIGSIZE = (8, 5)\n",
    "ax = line_df.plot(\n",
    "    kind=\"line\", figsize=FIGSIZE, marker='o', linewidth=2,\n",
    "    color=[\"royalblue\", \"darkorange\", \"purple\", \"seagreen\"]\n",
    ")\n",
    "\n",
    "# Titles and labels\n",
    "ax.set_title(\"Vessels per Year: Valid vs Removed\", fontsize=17, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Reporting Period\")\n",
    "ax.set_ylabel(\"Number of Vessels\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Grid and legend\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- Save figure ---\n",
    "fig_dir = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\"\n",
    "filename = \"Vessels_Line.svg\"\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf619c-792a-4a4b-b73e-fd99343d3fe8",
   "metadata": {},
   "source": [
    "## 3.2 Number of Ships per Category per Year + Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11cfaf7-0b05-44ea-bd3c-7515734d25a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------PIE CHART PLOT (PERCENTAGES)-----------------------------------------------------------------#\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# === Aggregate data ===\n",
    "ship_counts = filtered_data.groupby([\"Reporting Period\", \"Ship type\"]).size().reset_index(name=\"Count\")\n",
    "\n",
    "years = sorted(ship_counts[\"Reporting Period\"].unique())\n",
    "\n",
    "# --- Determine master order from 2018 (first year) ---\n",
    "first_year = years[0]\n",
    "data_2018 = ship_counts[ship_counts[\"Reporting Period\"] == first_year]\n",
    "ship_types_sorted = data_2018.sort_values(\"Count\", ascending=False)[\"Ship type\"].tolist()\n",
    "\n",
    "# Map ship types to consistent colors\n",
    "colors = plt.cm.tab20.colors[:len(ship_types_sorted)]\n",
    "color_map = {st: colors[i] for i, st in enumerate(ship_types_sorted)}\n",
    "\n",
    "# === Global style ===\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# === Create 2-row grid: 4 columns first row, 3 second row ===\n",
    "fig, axes = plt.subplots(2, 4, figsize=(17, 11.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    ax = axes[i]\n",
    "    data = ship_counts[ship_counts[\"Reporting Period\"] == year]\n",
    "    counts = [data[data[\"Ship type\"] == st][\"Count\"].sum() for st in ship_types_sorted]\n",
    "\n",
    "    total = sum(counts)\n",
    "    percentages = [(val / total) * 100 if total > 0 else 0 for val in counts]\n",
    "\n",
    "    wedges, texts = ax.pie(\n",
    "        counts,\n",
    "        labels=None,\n",
    "        startangle=90,\n",
    "        colors=[color_map[st] for st in ship_types_sorted],\n",
    "        wedgeprops=dict(width=0.6),\n",
    "        textprops={\"fontsize\": 19, \"fontname\": \"Times New Roman\"}\n",
    "    )\n",
    "\n",
    "    # Show percentages in the pie for the top 7 contributors\n",
    "    if len(percentages) >= 7:\n",
    "        top7_threshold = sorted(percentages, reverse=True)[6]\n",
    "    else:\n",
    "        top7_threshold = min(percentages)\n",
    "\n",
    "    for wedge, pct in zip(wedges, percentages):\n",
    "        if pct >= top7_threshold and pct > 0:\n",
    "            angle = (wedge.theta2 + wedge.theta1) / 2\n",
    "            x = 0.7 * np.cos(np.deg2rad(angle))\n",
    "            y = 0.7 * np.sin(np.deg2rad(angle))\n",
    "            ax.text(x, y, f\"{pct:.1f}%\", ha=\"center\", va=\"center\",\n",
    "                    fontsize=18, fontname=\"Times New Roman\")\n",
    "\n",
    "    ax.set_title(str(year), fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "# Hide the last axis (empty)\n",
    "axes[-1].axis('off')\n",
    "\n",
    "# === Legend in the same sorted order ===\n",
    "handles = [mpatches.Patch(facecolor=color_map[st], label=st) for st in ship_types_sorted]\n",
    "\n",
    "fig.legend(handles=handles,\n",
    "           loc='lower right',\n",
    "           ncol=1,\n",
    "           fontsize=15,\n",
    "           frameon=False,\n",
    "           bbox_to_anchor=(1, 0.08))\n",
    "\n",
    "# Big bold overall title\n",
    "plt.suptitle(\"Fleet Composition by Ship Type (2018-2024)\",\n",
    "             fontsize=24, fontweight=\"bold\")\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "\n",
    "# === Save as SVG ===\n",
    "fig_dir = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\"\n",
    "filename = \"Fleet_ShipType_PieCharts_Percentages.svg\"\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35c243-0da4-4f0a-ae6f-7a152c9834f1",
   "metadata": {},
   "source": [
    "## 3.3 Emissions-Consumption (per Distance) and per Category + Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff43783-046d-4339-a111-66dfb5f6712a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------ EMISSIONS AND CONSUMPTION PER DISTNACE FROM TOTAL ----------------------#\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "\n",
    "# ------------------------------ EMISSIONS AND CONSUMPTION PER DISTNACE FROM TOTAL ----------------------#\n",
    "yearly_Fuel_Consumption = filtered_data.groupby(\"Reporting Period\")[\"Total fuel consumption [m tonnes]\"].sum()\n",
    "yearly_Distance = filtered_data.groupby(\"Reporting Period\")[\"Annual Distance per Vessel [n miles]\"].sum()\n",
    "yearly_CO2_Emissions = filtered_data.groupby(\"Reporting Period\")[\"Total CO₂ emissions [m tonnes]\"].sum()\n",
    "\n",
    "# === Calculate intensity metrics ===\n",
    "fuel_per_distance = yearly_Fuel_Consumption / yearly_Distance\n",
    "co2_per_distance = yearly_CO2_Emissions / yearly_Distance\n",
    "\n",
    "# === Create 1 row × 2 column subplot ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5), sharex=True)\n",
    "\n",
    "fig.suptitle(\"Fuel and CO₂ Intensity per Distance Sailed From All Reported Vessels (2018–2024)\", \n",
    "             fontsize=19, fontweight=\"bold\")\n",
    "\n",
    "# Fuel per Distance (Blue)\n",
    "fuel_per_distance.plot(kind=\"line\", marker=\"o\", color=\"steelblue\", ax=axes[0])\n",
    "axes[0].set_title(\"Fuel Consumption per Distance\")\n",
    "axes[0].set_xlabel(\"Reporting Period\")\n",
    "axes[0].set_ylabel(\"Fuel [m tonnes / n mile]\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# CO₂ per Distance (Orange)\n",
    "co2_per_distance.plot(kind=\"line\", marker=\"o\", color=\"darkorange\", ax=axes[1])\n",
    "axes[1].set_title(\"CO₂ Emissions per Distance\")\n",
    "axes[1].set_xlabel(\"Reporting Period\")\n",
    "axes[1].set_ylabel(\"CO₂ [m tonnes / n mile]\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "# --- Save as SVG in same folder ---\n",
    "filename = \"Trend_Fuel_and_CO2_per_Distance.svg\"\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24523b8d-c167-4adb-bc3b-ca8b939f9c31",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------FUEL & CO2 BAR PLOTS PER CATEGORY---------------------------------------------------------#\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# === Aggregate data: sum per year & ship type ===\n",
    "fuel_counts = filtered_data.groupby([\"Reporting Period\", \"Ship type\"])[\"Total fuel consumption [m tonnes]\"].sum().reset_index()\n",
    "co2_counts = filtered_data.groupby([\"Reporting Period\", \"Ship type\"])[\"Total CO₂ emissions [m tonnes]\"].sum().reset_index()\n",
    "\n",
    "# === Pivot tables for plotting ===\n",
    "fuel_pivot = fuel_counts.pivot(index=\"Reporting Period\", columns=\"Ship type\", values=\"Total fuel consumption [m tonnes]\").fillna(0)\n",
    "fuel_pivot = fuel_pivot[ship_types_sorted]  # ensure consistent ship type order\n",
    "\n",
    "co2_pivot = co2_counts.pivot(index=\"Reporting Period\", columns=\"Ship type\", values=\"Total CO₂ emissions [m tonnes]\").fillna(0)\n",
    "co2_pivot = co2_pivot[ship_types_sorted]  # ensure consistent ship type order\n",
    "\n",
    "# === Plot grouped bar chart for Fuel Consumption ===\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "bar_width = 2\n",
    "padding = 0.5\n",
    "n_types = len(ship_types_sorted)\n",
    "x = np.arange(len(fuel_pivot.index)) * (bar_width + padding)\n",
    "\n",
    "for i, st in enumerate(ship_types_sorted):\n",
    "    ax.bar(x + i * bar_width / n_types,\n",
    "           fuel_pivot[st],\n",
    "           width=bar_width / n_types,\n",
    "           label=st,\n",
    "           color=color_map[st])\n",
    "\n",
    "ax.set_xticks(x + bar_width/2)\n",
    "ax.set_xticklabels(fuel_pivot.index, rotation=45)\n",
    "\n",
    "ax.set_title(\"Annual Fuel Consumption by Ship Type\", fontsize=16, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Reporting Period\")\n",
    "ax.set_ylabel(\"Fuel Consumption [m tonnes]\")\n",
    "\n",
    "ax.legend(\n",
    "    title=\"Ship Type\",\n",
    "    title_fontproperties=fm.FontProperties(weight=\"bold\", size=11),\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "\n",
    "# === Save as SVG ===\n",
    "filename = \"Fuel_Consumption_by_ShipType_and_Year_Bar_Plot.svg\"\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "# === Plot grouped bar chart for CO₂ Emissions ===\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "x = np.arange(len(co2_pivot.index)) * (bar_width + padding)\n",
    "\n",
    "for i, st in enumerate(ship_types_sorted):\n",
    "    ax.bar(x + i * bar_width / n_types,\n",
    "           co2_pivot[st],\n",
    "           width=bar_width / n_types,\n",
    "           label=st,\n",
    "           color=color_map[st])\n",
    "\n",
    "ax.set_xticks(x + bar_width/2)\n",
    "ax.set_xticklabels(co2_pivot.index, rotation=45)\n",
    "\n",
    "ax.set_title(\"Annual CO₂ Emissions by Ship Type\", fontsize=16, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Reporting Period\")\n",
    "ax.set_ylabel(\"CO₂ Emissions [m tonnes]\")\n",
    "\n",
    "ax.legend(\n",
    "    title=\"Ship Type\",\n",
    "    title_fontproperties=fm.FontProperties(weight=\"bold\", size=11),\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "\n",
    "# === Save as SVG ===\n",
    "filename = \"CO2_Emissions_by_ShipType_and_Year_Bar_Plot.svg\"\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "plt.show()\n",
    "#-----------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6856e-305c-4958-a3a4-ba96f2f7568e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------TOTAL DISTANCE BAR PLOTS PER CATEGORY---------------------------------------------------------#\n",
    "\n",
    "# === Aggregate data: sum per year & ship type ===\n",
    "agg_counts = filtered_data.groupby([\"Reporting Period\", \"Ship type\"]).agg({\"Annual Distance per Vessel [n miles]\": \"sum\"}).reset_index()\n",
    "\n",
    "# === Pivot table for Total Distance ===\n",
    "distance_pivot = agg_counts.pivot(index=\"Reporting Period\", columns=\"Ship type\", values=\"Annual Distance per Vessel [n miles]\").fillna(0)\n",
    "distance_pivot = distance_pivot[ship_types_sorted]\n",
    "\n",
    "# === Plot grouped bar chart for Total Distance ===\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "bar_width = 2\n",
    "padding = 0.5\n",
    "n_types = len(ship_types_sorted)\n",
    "x = np.arange(len(distance_pivot.index)) * (bar_width + padding)\n",
    "\n",
    "for i, st in enumerate(ship_types_sorted):\n",
    "    ax.bar(x + i * bar_width / n_types,\n",
    "           distance_pivot[st],\n",
    "           width=bar_width / n_types,\n",
    "           label=st,\n",
    "           color=color_map[st])\n",
    "\n",
    "ax.set_xticks(x + bar_width/2)\n",
    "ax.set_xticklabels(distance_pivot.index, rotation=45)\n",
    "\n",
    "ax.set_title(\"Total Distance Sailed by Ship Type\", fontsize=16, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Reporting Period\")\n",
    "ax.set_ylabel(\"Total Distance [n miles]\")\n",
    "\n",
    "ax.legend(\n",
    "    title=\"Ship Type\",\n",
    "    title_fontproperties=fm.FontProperties(weight=\"bold\", size=11),\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "\n",
    "# === Save as SVG ===\n",
    "filename = \"Total_Distance_by_ShipType_and_Year_Bar_Plot.svg\"\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393f972-b1e9-49f7-99ce-80403e24858b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#----------------------------- (FUEL & CO2) / DISTANCE - BAR PLOTS PER CATEGORY---------------------------------------------------------#\n",
    "\n",
    "#-----------------------------FUEL & CO2 PER MILE BAR PLOTS PER CATEGORY---------------------------------------------------------#\n",
    "\n",
    "# === Aggregate data: sum per year & ship type ===\n",
    "agg_counts = filtered_data.groupby([\"Reporting Period\", \"Ship type\"]).agg({\n",
    "    \"Total fuel consumption [m tonnes]\": \"sum\",\n",
    "    \"Total CO₂ emissions [m tonnes]\": \"sum\",\n",
    "    \"Annual Distance per Vessel [n miles]\": \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "# === Pivot tables for plotting ===\n",
    "fuel_per_mile_pivot = (agg_counts.pivot(index=\"Reporting Period\", columns=\"Ship type\", values=\"Total fuel consumption [m tonnes]\") / \n",
    "                       agg_counts.pivot(index=\"Reporting Period\", columns=\"Ship type\", values=\"Annual Distance per Vessel [n miles]\")).fillna(0)\n",
    "fuel_per_mile_pivot = fuel_per_mile_pivot[ship_types_sorted]  # ensure consistent ship type order\n",
    "\n",
    "co2_per_mile_pivot = (agg_counts.pivot(index=\"Reporting Period\", columns=\"Ship type\", values=\"Total CO₂ emissions [m tonnes]\") / \n",
    "                      agg_counts.pivot(index=\"Reporting Period\", columns=\"Ship type\", values=\"Annual Distance per Vessel [n miles]\")).fillna(0)\n",
    "co2_per_mile_pivot = co2_per_mile_pivot[ship_types_sorted]  # ensure consistent ship type order\n",
    "\n",
    "# === Plot grouped bar chart for Fuel per Mile ===\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "bar_width = 2\n",
    "padding = 0.5\n",
    "n_types = len(ship_types_sorted)\n",
    "x = np.arange(len(fuel_per_mile_pivot.index)) * (bar_width + padding)\n",
    "\n",
    "for i, st in enumerate(ship_types_sorted):\n",
    "    ax.bar(x + i * bar_width / n_types,\n",
    "           fuel_per_mile_pivot[st],\n",
    "           width=bar_width / n_types,\n",
    "           label=st,\n",
    "           color=color_map[st])\n",
    "\n",
    "ax.set_xticks(x + bar_width/2)\n",
    "ax.set_xticklabels(fuel_per_mile_pivot.index, rotation=45)\n",
    "\n",
    "ax.set_title(\"Fuel Consumption per Distance by Ship Type\", fontsize=16, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Reporting Period\")\n",
    "ax.set_ylabel(\"Fuel Consumption [m tonnes / n miles]\")\n",
    "\n",
    "ax.legend(\n",
    "    title=\"Ship Type\",\n",
    "    title_fontproperties=fm.FontProperties(weight=\"bold\", size=11),\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "\n",
    "# === Save as SVG ===\n",
    "filename = \"Fuel_per_Mile_by_ShipType_and_Year_Bar_Plot.svg\"\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "# === Plot grouped bar chart for CO₂ per Mile ===\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "x = np.arange(len(co2_per_mile_pivot.index)) * (bar_width + padding)\n",
    "\n",
    "for i, st in enumerate(ship_types_sorted):\n",
    "    ax.bar(x + i * bar_width / n_types,\n",
    "           co2_per_mile_pivot[st],\n",
    "           width=bar_width / n_types,\n",
    "           label=st,\n",
    "           color=color_map[st])\n",
    "\n",
    "ax.set_xticks(x + bar_width/2)\n",
    "ax.set_xticklabels(co2_per_mile_pivot.index, rotation=45)\n",
    "\n",
    "ax.set_title(\"CO₂ Emissions per Distance by Ship Type\", fontsize=16, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Reporting Period\")\n",
    "ax.set_ylabel(\"CO₂ Emissions [m tonnes / n miles]\")\n",
    "\n",
    "ax.legend(\n",
    "    title=\"Ship Type\",\n",
    "    title_fontproperties=fm.FontProperties(weight=\"bold\", size=11),\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "\n",
    "# === Save as SVG ===\n",
    "filename = \"CO2_per_Mile_by_ShipType_and_Year_Bar_Plot.svg\"\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "plt.show()\n",
    "#-----------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50bdd5-5d6b-48ab-9df6-37bada5db44e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#----------------------------- FUEL & CO₂ EMISSIONS PIE CHARTS (PERCENTAGES, CONSISTENT COLORS) -----------------------------#\n",
    "\n",
    "# === Aggregate data ===\n",
    "agg_counts = filtered_data.groupby([\"Reporting Period\", \"Ship type\"]).agg({\n",
    "    \"Total fuel consumption [m tonnes]\": \"sum\",\n",
    "    \"Total CO₂ emissions [m tonnes]\": \"sum\",\n",
    "    \"Annual Distance per Vessel [n miles]\": \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "# Function to plot pie charts\n",
    "def plot_pie_grid(pivot_df, title_prefix, filename, top_n_label=7, n_cols=4):\n",
    "    years = sorted(pivot_df.index)\n",
    "    n_rows = int(np.ceil(len(years) / n_cols))\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(17, 11.5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, year in enumerate(years):\n",
    "        ax = axes[i]\n",
    "        data = pivot_df.loc[year]\n",
    "\n",
    "        # Sort ship types by descending value for this year\n",
    "        sorted_types = data.sort_values(ascending=False).index.tolist()\n",
    "        counts = [data[st] for st in sorted_types]\n",
    "\n",
    "        total = sum(counts)\n",
    "        percentages = [(val / total) * 100 if total > 0 else 0 for val in counts]\n",
    "\n",
    "        # Pie chart using MASTER color_map\n",
    "        wedges, texts = ax.pie(\n",
    "            counts,\n",
    "            labels=None,\n",
    "            startangle=90,\n",
    "            colors=[color_map[st] for st in sorted_types],  # consistent colors\n",
    "            wedgeprops=dict(width=0.6),\n",
    "            textprops={\"fontsize\": 19, \"fontname\": \"Times New Roman\"}\n",
    "        )\n",
    "\n",
    "        # Label top N contributors with percentages\n",
    "        if len(percentages) >= top_n_label:\n",
    "            threshold = sorted(percentages, reverse=True)[top_n_label - 1]\n",
    "        else:\n",
    "            threshold = min(percentages) if percentages else 0\n",
    "\n",
    "        for wedge, pct in zip(wedges, percentages):\n",
    "            if pct >= threshold and pct > 0:\n",
    "                angle = (wedge.theta2 + wedge.theta1) / 2\n",
    "                x = 0.7 * np.cos(np.deg2rad(angle))\n",
    "                y = 0.7 * np.sin(np.deg2rad(angle))\n",
    "                ax.text(x, y, f\"{pct:.1f}%\", ha=\"center\", va=\"center\",\n",
    "                        fontsize=18, fontname=\"Times New Roman\")\n",
    "\n",
    "        ax.set_title(str(year), fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "    # Hide extra axes\n",
    "    for j in range(len(years), len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Legend in master order\n",
    "    handles = [mpatches.Patch(facecolor=color_map[st], label=st) for st in ship_types_sorted]\n",
    "    fig.legend(handles=handles,\n",
    "               loc='lower right',\n",
    "               ncol=1,\n",
    "               fontsize=15,\n",
    "               frameon=False,\n",
    "               bbox_to_anchor=(1, 0.08))\n",
    "\n",
    "    plt.suptitle(f\"{title_prefix} ({years[0]}–{years[-1]})\",\n",
    "                 fontsize=24, fontweight=\"bold\")\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "\n",
    "    # Save\n",
    "    save_path = os.path.join(fig_dir, filename)\n",
    "    plt.savefig(save_path, format=\"svg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# === Pivot tables for Fuel and CO₂ ===\n",
    "fuel_pivot = agg_counts.pivot(index=\"Reporting Period\", columns=\"Ship type\",\n",
    "                              values=\"Total fuel consumption [m tonnes]\").fillna(0)\n",
    "\n",
    "co2_pivot = agg_counts.pivot(index=\"Reporting Period\", columns=\"Ship type\",\n",
    "                             values=\"Total CO₂ emissions [m tonnes]\").fillna(0)\n",
    "\n",
    "# === Plot Fuel Consumption pies ===\n",
    "plot_pie_grid(fuel_pivot,\n",
    "              title_prefix=\"Fuel Consumption Share by Ship Type\",\n",
    "              filename=\"Fuel_Consumption_Share_by_ShipType_and_Year_PieCharts.svg\")\n",
    "\n",
    "# === Plot CO₂ Emissions pies ===\n",
    "plot_pie_grid(co2_pivot,\n",
    "              title_prefix=\"CO₂ Emissions Share by Ship Type\",\n",
    "              filename=\"CO2_Emissions_Share_by_ShipType_and_Year_PieCharts.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ef0bc-45b4-4fe8-9f8f-a820e860e7fb",
   "metadata": {},
   "source": [
    "## 3.4 Measurement Methods + Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc10260-80fa-4e07-9a82-d168ce5fab36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "A_count = filtered_data.groupby(\"Reporting Period\")[\"A\"].agg(lambda x: (x == \"Yes\").sum())\n",
    "B_count = filtered_data.groupby(\"Reporting Period\")[\"B\"].agg(lambda x: (x == \"Yes\").sum())\n",
    "C_count = filtered_data.groupby(\"Reporting Period\")[\"C\"].agg(lambda x: (x == \"Yes\").sum())\n",
    "D_count = filtered_data.groupby(\"Reporting Period\")[\"D\"].agg(lambda x: (x == \"Yes\").sum())\n",
    "total_methods = A_count + B_count + C_count + D_count\n",
    "\n",
    "# === Combine into a DataFrame for stacked bar plot ===\n",
    "stacked_df = pd.concat([A_count, B_count, C_count, D_count], axis=1)\n",
    "stacked_df.columns = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "# === Global style ===\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "plt.rcParams[\"axes.labelsize\"] = 13\n",
    "plt.rcParams[\"xtick.labelsize\"] = 11\n",
    "plt.rcParams[\"ytick.labelsize\"] = 11\n",
    "\n",
    "# === Plot stacked bar chart ===\n",
    "FIGSIZE = (8, 5)\n",
    "ax = stacked_df.plot(kind=\"bar\", stacked=True, figsize=FIGSIZE,\n",
    "                     color=[\"steelblue\", \"darkorange\", \"seagreen\", \"purple\"])\n",
    "\n",
    "ax.set_title(\"Total Methods per Year\")\n",
    "ax.set_xlabel(\"Reporting Period\")\n",
    "ax.set_ylabel(\"Number of Methods Used\")\n",
    "plt.xticks(rotation=45)\n",
    "# Add grid\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.7)  # horizontal grid lines\n",
    "# Make legend smaller\n",
    "ax.legend(fontsize=9)  # adjust the number as needed\n",
    "plt.tight_layout()\n",
    "\n",
    "# === Save as SVG ===\n",
    "fig_dir = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\"\n",
    "filename = \"Total_Methods_Stacked.svg\"\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a600a64-0b48-4066-b638-032c4892a0f6",
   "metadata": {},
   "source": [
    "## 3.5 Annual Total Fuel, CO2, Distance and Average Speed + Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c78ef-f2d9-4233-b116-8f0ec997de4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Group by Year and sum\n",
    "yearly_Fuel_Consumption = filtered_data.groupby(\"Reporting Period\")[\"Total fuel consumption [m tonnes]\"].sum()\n",
    "yearly_CO2_Emissions = filtered_data.groupby(\"Reporting Period\")[\"Total CO₂ emissions [m tonnes]\"].sum()\n",
    "yearly_Distance = filtered_data.groupby(\"Reporting Period\")[\"Annual Distance per Vessel [n miles]\"].sum()\n",
    "yearly_Average_speed = filtered_data.groupby(\"Reporting Period\")[\"Annual Average Speed per Vessel [knots]\"].mean()\n",
    "\n",
    "# Set global style: Times New Roman everywhere\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"axes.titlesize\"] = 16   # bigger titles\n",
    "plt.rcParams[\"axes.labelsize\"] = 13   # axis labels slightly smaller\n",
    "plt.rcParams[\"xtick.labelsize\"] = 11  # tick labels smaller\n",
    "plt.rcParams[\"ytick.labelsize\"] = 11\n",
    "\n",
    "# Fixed size for consistency\n",
    "#FIGSIZE = (8, 5)\n",
    "\n",
    "# === Create 3 subplots ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 8), sharex=True)\n",
    "# Flatten axes array for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "fig.suptitle(\"Fuel, CO₂, Distance and Average Speed From All Reported Vessels (2018–2024)\", \n",
    "             fontsize=19, fontweight=\"bold\")\n",
    "\n",
    "# Fuel Consumption (Blue)\n",
    "yearly_Fuel_Consumption.plot(kind=\"line\", marker=\"o\", color=\"steelblue\", ax=axes[0])\n",
    "axes[0].set_title(\"Annual Fuel Consumption\")\n",
    "axes[0].set_ylabel(\"Fuel Mass [m tonnes]\")\n",
    "axes[0].set_xlabel(\"Year\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# CO₂ Emissions (Orange)\n",
    "yearly_CO2_Emissions.plot(kind=\"line\", marker=\"o\", color=\"darkorange\", ax=axes[1])\n",
    "axes[1].set_title(\"Annual CO₂ Emissions\")\n",
    "axes[1].set_xlabel(\"Year\")\n",
    "axes[1].set_ylabel(\"CO₂ Mass [m tonnes]\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Distance (Green)\n",
    "yearly_Distance.plot(kind=\"line\", marker=\"o\", color=\"seagreen\", ax=axes[2])\n",
    "axes[2].set_title(\"Annual Distance Sailed\")\n",
    "axes[2].set_xlabel(\"Year\")\n",
    "axes[2].set_ylabel(\"Distance [n miles]\")\n",
    "axes[2].grid(True)\n",
    "\n",
    "# Speed (Magenta)\n",
    "yearly_Average_speed.plot(kind=\"line\", marker=\"o\", color=\"darkmagenta\", ax=axes[3])\n",
    "axes[3].set_title(\"Annual Average Speed\")\n",
    "axes[3].set_xlabel(\"Reporting Period\")\n",
    "axes[3].set_ylabel(\"Speed [knots]\")\n",
    "axes[3].grid(True)\n",
    "\n",
    "# ----Figures folder (give once)----\n",
    "fig_dir = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\"\n",
    "\n",
    "#-----SAVE-----------#\n",
    "filename = \"Trend of Fuel CO2 and Distance and Speed.svg\"   # <-- only change this part per figure\n",
    "save_path = os.path.join(fig_dir, filename)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path, format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed6cf40-688f-4ff0-8404-18cace2f2df9",
   "metadata": {},
   "source": [
    "# 4. Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aebe99-cab1-4ca9-928d-661b8ff3c4d8",
   "metadata": {},
   "source": [
    "## 4.1 For Each year & Whole Period: Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09dafef-c1cc-4d9a-8456-b10aceed7a64",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------- BASIC STATISTCS PER YEAR AND WHOLE PERIOD: WEIGHTED MEAN + STD, MIN, MAX, S, K------------------------------------#\n",
    "\n",
    "#------------------------------- WEIGHTED MEAN + STD, MIN, MAX, S, K----------------------------------------------#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Function for weighted mean & weighted std\n",
    "def weighted_stats(values, weights):\n",
    "    w_mean = np.average(values, weights=weights)\n",
    "    w_var = np.average((values - w_mean) ** 2, weights=weights)\n",
    "    w_std = np.sqrt(w_var)\n",
    "    return w_mean, w_std\n",
    "\n",
    "# Main function to compute statistics\n",
    "def compute_stats(filtered_data):\n",
    "    results = []\n",
    "\n",
    "    for (year, ship_type), group in filtered_data.groupby([\"Reporting Period\", \"Ship type\"]):\n",
    "        values = group[\"Annual average Fuel consumption per distance [kg / n mile]\"]\n",
    "        total_fuel = group[\"Total fuel consumption [m tonnes]\"].sum()\n",
    "        weights = (group[\"Total fuel consumption [m tonnes]\"] / total_fuel).values\n",
    "\n",
    "        # Weighted mean & std\n",
    "        w_mean, w_std = weighted_stats(values.values, weights)\n",
    "\n",
    "        # Unweighted stats\n",
    "        results.append({\n",
    "            \"Year\": year,\n",
    "            \"Ship Type\": ship_type,\n",
    "            \"Weighted Mean\": w_mean,\n",
    "            \"Weighted SD\": w_std,\n",
    "            \"Median\": values.median(),\n",
    "            \"Min\": values.min(),\n",
    "            \"Max\": values.max(),\n",
    "            \"Skewness\": skew(values, bias=False),\n",
    "            \"Kurtosis\": kurtosis(values, bias=False),\n",
    "        })\n",
    "\n",
    "    stats_df = pd.DataFrame(results)\n",
    "    return stats_df.sort_values([\"Year\", \"Weighted Mean\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "# Results\n",
    "stats_per_year = compute_stats(filtered_data)\n",
    "\n",
    "#------------------------------- WEIGHTED STATS PER SHIP TYPE ACROSS ALL YEARS -------------------------------#\n",
    "def compute_stats_all_years(filtered_data):\n",
    "    results = []\n",
    "\n",
    "    for ship_type, group in filtered_data.groupby(\"Ship type\"):\n",
    "        values = group[\"Annual average Fuel consumption per distance [kg / n mile]\"]\n",
    "        total_fuel = group[\"Total fuel consumption [m tonnes]\"].sum()\n",
    "        weights = (group[\"Total fuel consumption [m tonnes]\"] / total_fuel).values\n",
    "\n",
    "        # Weighted mean & std\n",
    "        w_mean, w_std = weighted_stats(values.values, weights)\n",
    "\n",
    "        # Unweighted stats\n",
    "        results.append({\n",
    "            \"Ship Type\": ship_type,\n",
    "            \"Weighted Mean\": w_mean,\n",
    "            \"Weighted SD\": w_std,\n",
    "            \"Median\": values.median(),\n",
    "            \"Min\": values.min(),\n",
    "            \"Max\": values.max(),\n",
    "            \"Skewness\": skew(values, bias=False),\n",
    "            \"Kurtosis\": kurtosis(values, bias=False),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(\"Weighted Mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Run computation\n",
    "stats_all_years = compute_stats_all_years(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f0f2d-a718-4155-850f-2589a0ede558",
   "metadata": {},
   "source": [
    "## 4.2 For Each year & Whole Period: CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c895bf-0935-430b-bfa1-eeea83935344",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------- BASIC STATISTCS PER YEAR AND WHOLE PERIOD: WEIGHTED MEAN + STD, MIN, MAX, S, K------------------------------------#\n",
    "\n",
    "#------------------------------- SAME BUT FOR CO2----------------------------------------------#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "#------------------------------- WEIGHTED STATS PER SHIP TYPE ACROSS ALL YEARS -------------------------------#\n",
    "def compute_stats_all_years_CO2(filtered_data):\n",
    "    results = []\n",
    "\n",
    "    for ship_type, group in filtered_data.groupby(\"Ship type\"):\n",
    "        values = group[\"Annual average CO₂ emissions per distance [kg CO₂ / n mile]\"]\n",
    "        total_fuel = group[\"Total CO₂ emissions [m tonnes]\"].sum()\n",
    "        weights = (group[\"Total CO₂ emissions [m tonnes]\"] / total_fuel).values\n",
    "\n",
    "        # Weighted mean & std\n",
    "        w_mean, w_std = weighted_stats(values.values, weights)\n",
    "\n",
    "        # Unweighted stats\n",
    "        results.append({\n",
    "            \"Ship Type\": ship_type,\n",
    "            \"Weighted Mean\": w_mean,\n",
    "            \"Weighted SD\": w_std,\n",
    "            \"Median\": values.median(),\n",
    "            \"Min\": values.min(),\n",
    "            \"Max\": values.max(),\n",
    "            \"Skewness\": skew(values, bias=False),\n",
    "            \"Kurtosis\": kurtosis(values, bias=False),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(\"Weighted Mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Run computation\n",
    "stats_CO2_all_years = compute_stats_all_years_CO2(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c64f6c-b705-4f40-9a28-eb5caab1484f",
   "metadata": {},
   "source": [
    "## 4.3 Export to Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103cb3e-5200-403a-970b-85822f80c561",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ------ EXPORT TABLES TO WORD -----------#\n",
    "from docx import Document\n",
    "\n",
    "#----FUNCTION FOR EXPORTING TO WORD-------#\n",
    "def df_to_word(df, filename=\"output.docx\"):\n",
    "    doc = Document()\n",
    "\n",
    "    # Add title\n",
    "    doc.add_heading(\"Ship Fuel Consumption Statistics\", level=1)\n",
    "\n",
    "    # Create table with extra row for headers\n",
    "    table = doc.add_table(rows=1, cols=len(df.columns))\n",
    "    table.style = \"Table Grid\"\n",
    "\n",
    "    # Add headers\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    for i, col_name in enumerate(df.columns):\n",
    "        hdr_cells[i].text = str(col_name)\n",
    "\n",
    "    # Add rows\n",
    "    for _, row in df.iterrows():\n",
    "        row_cells = table.add_row().cells\n",
    "        for i, val in enumerate(row):\n",
    "            # Format floats to 2 decimals\n",
    "            if isinstance(val, (int, float)):\n",
    "                row_cells[i].text = f\"{val:.2f}\"\n",
    "            else:\n",
    "                row_cells[i].text = str(val)\n",
    "\n",
    "    # Save file\n",
    "    doc.save(filename)\n",
    "#----------------------------------------------------#\n",
    "\n",
    "# Example usage\n",
    "df_to_word(stats_CO2_all_years, \"stats_CO2_all_years.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39312da-da11-4bee-bda1-7cbc27f0c99a",
   "metadata": {},
   "source": [
    "# 5. Basic Statistics on Efficieny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de4d17e-d7e7-4071-a043-91d57f93e491",
   "metadata": {},
   "source": [
    "## 5.1 FILTERING on Efficieny for the desired 4 ship types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046cdf9-b079-404d-8ba6-d1e213c30ac6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- FILTER ON EFFICIENCY FOR 4 SHIP CATEGORIES---#\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "ship_types = [\"Bulk carrier\", \"Oil tanker\", \"Container ship\", \"Chemical tanker\"]\n",
    "\n",
    "x_col = \"Technical efficiency Index Value [gCO₂/t·nm]\"\n",
    "y_col = \"Annual average CO₂ emissions per transport work (mass) [g CO₂ / m tonnes · n miles]\"\n",
    "cols_to_filter_by = [y_col, x_col]\n",
    "\n",
    "# --- Filtering across all ship types at once ---\n",
    "outlier_counts, thresholds, all_filtered_data = count_outliers_by_group_two_cols(\n",
    "    filtered_data,\n",
    "    cols=cols_to_filter_by,\n",
    "    group_col=\"Ship type\",\n",
    "    lower=0.025,\n",
    "    upper=0.975,\n",
    "    return_filtered=True\n",
    ")\n",
    "\n",
    "# --- Print summary of filtering --- #\n",
    "for ship_type in ship_types:\n",
    "    total_ship_rows = len(filtered_data[filtered_data[\"Ship type\"] == ship_type])\n",
    "    remaining_rows = len(all_filtered_data[all_filtered_data[\"Ship type\"] == ship_type])\n",
    "\n",
    "    print(f\"\\n================= {ship_type} =================\")\n",
    "    print(f\"{ship_type} rows before filtering: {total_ship_rows}\")\n",
    "    print(f\"{ship_type} rows after filtering: {remaining_rows}\")\n",
    "\n",
    "# Use filtered data for analysis\n",
    "filtered_data_efficiency = all_filtered_data\n",
    "\n",
    "# Keep only the desired \"Ship Types\"\n",
    "filtered_data_efficiency = all_filtered_data[\n",
    "    all_filtered_data[\"Ship type\"].isin(ship_types)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5d0a0-7443-4d28-8652-0ad924cf3517",
   "metadata": {},
   "source": [
    "## 5.2 Descriptive Statistics before Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cbb50c-e662-46e2-86a8-40727c35e14f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "import pandas as pd\n",
    "\n",
    "def compute_descriptive_stats(df, vars_list, group_col=None, corr_ref=None):\n",
    "    \"\"\"\n",
    "    Compute descriptive statistics for a list of numeric variables.\n",
    "    If group_col is provided, compute per group; otherwise overall.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # If grouping column is given, group; else treat as single group\n",
    "    grouped = df.groupby(group_col) if group_col else [(None, df)]\n",
    "\n",
    "    for group_name, group in grouped:\n",
    "        for var in vars_list:\n",
    "            data = group[var].dropna()\n",
    "            stats = {\n",
    "                \"Group\": group_name if group_col else \"Overall\",\n",
    "                \"Variable\": var,\n",
    "                \"Mean\": data.mean(),\n",
    "                \"SD\": data.std(),\n",
    "                \"Median\": data.median(),\n",
    "                \"Min\": data.min(),\n",
    "                \"Max\": data.max(),\n",
    "                \"Skewness\": skew(data, bias=False),\n",
    "                \"Kurtosis\": kurtosis(data, bias=False)\n",
    "            }\n",
    "\n",
    "            if corr_ref and corr_ref in group.columns and var != corr_ref:\n",
    "                corr_xy = group[[var, corr_ref]].corr().iloc[0, 1]\n",
    "                stats[f\"Correlation (vs. {corr_ref})\"] = round(corr_xy, 2)\n",
    "            else:\n",
    "                stats[f\"Correlation (vs. {corr_ref})\"] = None\n",
    "\n",
    "            results.append(stats)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage:\n",
    "#desc = compute_descriptive_stats(\n",
    "#    filtered_data_efficiency,\n",
    "#    vars_list=[\n",
    " #       \"Technical efficiency Index Value [gCO₂/t·nm]\",\n",
    " #       \"Annual average CO₂ emissions per transport work (mass) [g CO₂ / m tonnes · n miles]\",\n",
    " #       \"Speed [knots]\",\n",
    " #       \"Age [years]\",\n",
    " #       \"DWT [t]\"\n",
    " #   ],\n",
    " #   group_col=\"Ship type\",\n",
    " #   corr_ref=\"Technical efficiency Index Value [gCO₂/t·nm]\"  # optional\n",
    "#)\n",
    "\n",
    "# Round and display nicely\n",
    "#print(desc.round(2).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33fc14-670a-4c6c-b1b6-e6b2d99ac421",
   "metadata": {},
   "source": [
    "# 6. Prepare Panel for Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07380b8-2a73-4e9a-8d7b-af2c6c41a59a",
   "metadata": {},
   "source": [
    "## 6.1 Import List Data - IMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcca18c-f8c5-4c3b-b30e-7069430a6987",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Original_Data\\ListIMO.xlsx\"\n",
    "\n",
    "# Read Excel file, assuming first row contains headers\n",
    "data_list = pd.read_excel(file_path, header=0)  # header=0 means first row is column names\n",
    "\n",
    "# Drop rows where 'IMO Number' is NaN\n",
    "data_list_clean = data_list.dropna(subset=['IMO Number'])\n",
    "\n",
    "# Optional: reset the index after dropping rows\n",
    "data_list_clean.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f2b8d-fc2b-4f90-8d59-e83d228218df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## 6.2 Match IMO Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4f922-9e8e-48a6-a1e4-c52bf4bc676e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge the two data frames on 'IMO Number'\n",
    "combined_df = pd.merge(\n",
    "    data_list_clean,                # List\n",
    "    filtered_data_efficiency,       # Filtered Data (only the DESIRED SHIP CATEGORIES)\n",
    "    on='IMO Number',                # column to join on\n",
    "    how='inner'                     # only keep rows with IMO Numbers in both\n",
    ")\n",
    "\n",
    "# Select only the columns we want\n",
    "# For example, keeping:\n",
    "# 'Ship type', 'IMO Number', 'DWT', 'Year of Built' from data_list_clean\n",
    "# and 'Name', 'Technical efficiency Index Value [gCO₂/t·nm]', \n",
    "# 'Annual average CO₂ emissions per transport work (mass) [g CO₂ / m tonnes · n miles]', \n",
    "# 'Annual Average Speed per Vessel [knots]' from filtered_data_efficiency\n",
    "\n",
    "columns_to_keep = [\n",
    "    'Ship type', 'IMO Number','Name', 'Reporting Period',\n",
    "    'DWT', 'Built',\n",
    "    'Technical efficiency Index Value [gCO₂/t·nm]',\n",
    "    'Annual average CO₂ emissions per transport work (mass) [g CO₂ / m tonnes · n miles]',\n",
    "    'Annual Average Speed per Vessel [knots]'\n",
    "]\n",
    "\n",
    "combined_df = combined_df[columns_to_keep]\n",
    "\n",
    "# Assuming 'Reporting Period' and 'Year of Built' are numeric\n",
    "combined_df['Age'] = combined_df['Reporting Period'] - combined_df['Built']\n",
    "\n",
    "# Check the result\n",
    "print(combined_df.head())\n",
    "print(combined_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5908a2-3fb0-4653-bc9d-55245d9d1b5c",
   "metadata": {},
   "source": [
    "### 6.2.1 Umatched vessels per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187464b-d30b-4cee-9e9b-73533c7166eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Count total vessels per Reporting Period and ship type\n",
    "total_counts = (\n",
    "    filtered_data_efficiency\n",
    "    .groupby(['Reporting Period', 'Ship type'])['IMO Number']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    ")\n",
    "total_counts.rename(columns={'IMO Number': 'Total Vessels'}, inplace=True)\n",
    "\n",
    "# Step 2: Count matched vessels per Reporting Period and ship type\n",
    "matched_counts = (\n",
    "    combined_df\n",
    "    .groupby(['Reporting Period', 'Ship type'])['IMO Number']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    ")\n",
    "matched_counts.rename(columns={'IMO Number': 'Matched Vessels'}, inplace=True)\n",
    "\n",
    "# Step 3: Merge total and matched counts\n",
    "report_df = pd.merge(\n",
    "    total_counts,\n",
    "    matched_counts,\n",
    "    on=['Reporting Period', 'Ship type'],\n",
    "    how='left'\n",
    ")\n",
    "report_df['Matched Vessels'] = report_df['Matched Vessels'].fillna(0)\n",
    "\n",
    "# Step 4: Calculate unmatched vessels\n",
    "report_df['Unmatched Vessels'] = report_df['Total Vessels'] - report_df['Matched Vessels']\n",
    "\n",
    "# Step 5: Filter only rows with unmatched vessels\n",
    "unmatched_df = report_df[report_df['Unmatched Vessels'] > 0]\n",
    "\n",
    "# Step 6: Pivot table for unmatched vessels\n",
    "unmatched_pivot = unmatched_df.pivot_table(\n",
    "    index='Ship type',\n",
    "    columns='Reporting Period',\n",
    "    values='Unmatched Vessels',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Ensure year columns are integers\n",
    "unmatched_pivot.columns = unmatched_pivot.columns.astype(int)\n",
    "\n",
    "# Reorder columns in descending order\n",
    "unmatched_pivot_filtered = unmatched_pivot[sorted(unmatched_pivot.columns, reverse=True)].copy()\n",
    "\n",
    "# Step 7: Calculate fleet averages from total vessels\n",
    "total_pivot = total_counts.pivot_table(\n",
    "    index='Ship type',\n",
    "    columns='Reporting Period',\n",
    "    values='Total Vessels',\n",
    "    fill_value=0\n",
    ")\n",
    "total_pivot.columns = total_pivot.columns.astype(int)\n",
    "total_pivot_filtered = total_pivot[sorted(total_pivot.columns, reverse=True)].copy()\n",
    "\n",
    "# Add average and std of fleet size\n",
    "unmatched_pivot_filtered['Fleet Time Average'] = total_pivot_filtered.mean(axis=1)\n",
    "unmatched_pivot_filtered['Fleet STD'] = total_pivot_filtered.std(axis=1)\n",
    "\n",
    "# Sort ship types alphabetically\n",
    "unmatched_pivot_filtered.sort_index(inplace=True)\n",
    "\n",
    "# Format numbers to 2 decimals\n",
    "unmatched_pivot_filtered = unmatched_pivot_filtered.round(2)\n",
    "\n",
    "# Print with a title\n",
    "print(\"\\n========== Unmatched IMO Numbers ==========\\n\")\n",
    "unmatched_pivot_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a08ee-97fb-47f4-9a07-1797fe059cde",
   "metadata": {},
   "source": [
    "## 6.3 Panel Dataframe: Categories and Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f79d93-e49f-4560-b1f7-fa8a328a752b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#----- function of classification regarding DWT ------------#\n",
    "\n",
    "def classify_vessel(row):\n",
    "    dwt = row[\"DWT\"]\n",
    "    ship_type = row[\"Ship type\"]\n",
    "\n",
    "    # Bulk carriers\n",
    "    if ship_type == \"Bulk carrier\":\n",
    "        if dwt < 24000:\n",
    "            return \"Mini Bulk Carrier\"\n",
    "        elif dwt < 35000:\n",
    "            return \"Handysize\"\n",
    "        elif dwt < 50000:\n",
    "            return \"Handymax\"\n",
    "        elif dwt < 61000:\n",
    "            return \"Supramax\"\n",
    "        elif dwt < 80000:\n",
    "            return \"Panamax\"\n",
    "        else:\n",
    "            return \"Capesize\" #there were a frew VLBC that is why they are combined\n",
    "    \n",
    "    # Oil tankers\n",
    "    elif ship_type == \"Oil tanker\":\n",
    "        if dwt < 37000:\n",
    "            return \"Handysize\"\n",
    "        elif dwt < 45000:\n",
    "            return \"MR1\"\n",
    "        elif dwt < 55000:\n",
    "            return \"MR2\"\n",
    "        elif dwt < 80000:\n",
    "            return \"Panamax\"\n",
    "        elif dwt < 120000:\n",
    "            return \"Aframax\"\n",
    "        elif dwt < 160000:\n",
    "            return \"Suezmax\"\n",
    "        else:\n",
    "            return \"VLCC\" #there were a frew ULCC that is why they are combined\n",
    "\n",
    "    # Chemical tankers\n",
    "    elif ship_type == \"Chemical tanker\":\n",
    "        if dwt < 37000:\n",
    "            return \"Handysize\"\n",
    "        elif dwt < 45000:\n",
    "            return \"MR1\"\n",
    "        elif dwt < 55000:\n",
    "            return \"MR2\"\n",
    "        elif dwt < 80000:\n",
    "            return \"LR1\"\n",
    "        elif dwt < 120000:\n",
    "            return \"LR2\"\n",
    "        elif dwt < 160000:\n",
    "            return \"Suezmax\"\n",
    "        else:\n",
    "            return \"VLCC\" #there were no ULCC that is why they are combined\n",
    "\n",
    "    # Container ships (approximate by DWT) - used an approximate factor of 13 between TEUs and DWT\n",
    "    elif ship_type == \"Container ship\":\n",
    "        if dwt < 20000:\n",
    "            return \"Feeder\"\n",
    "        elif dwt < 40000:\n",
    "            return \"Feedermax\"\n",
    "        elif dwt < 65000:\n",
    "            return \"Panamax\"\n",
    "        elif dwt < 90000:\n",
    "            return \"Post-Panamax\"\n",
    "        elif dwt < 120000:\n",
    "            return \"Neo-Panamax\"\n",
    "        else:\n",
    "            return \"ULCV\"\n",
    "\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5ecbe-ec9b-4691-9eaa-16e87cb26f16",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----- !! REORDER AND RENAME COLUMNS !! ----------#\n",
    "\n",
    "# Step 1: Reorder columns and drop 'Built'\n",
    "panel_df = combined_df[\n",
    "    [\"Ship type\",\"Name\",\"IMO Number\", \"Reporting Period\",\n",
    "     \"Annual average CO₂ emissions per transport work (mass) [g CO₂ / m tonnes · n miles]\", \n",
    "     \"Technical efficiency Index Value [gCO₂/t·nm]\", \n",
    "     \"Age\", \"DWT\",\n",
    "     \"Annual Average Speed per Vessel [knots]\"]\n",
    "]\n",
    "\n",
    "# Step 2: Rename columns\n",
    "panel_df = panel_df.rename(columns={\n",
    "    \"Technical efficiency Index Value [gCO₂/t·nm]\": \"TEI\",\n",
    "    \"Annual average CO₂ emissions per transport work (mass) [g CO₂ / m tonnes · n miles]\": \"CO2 Eff.\",\n",
    "    \"Annual Average Speed per Vessel [knots]\": \"Speed\"\n",
    "})\n",
    "\n",
    "# Step 3: Sorting by Ship type, IMO Number, and Reporting Period\n",
    "panel_df = panel_df.sort_values(\n",
    "    by=[\"Ship type\", \"IMO Number\", \"Reporting Period\"],\n",
    "    ascending=[True, True, True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Step 4: Add \"Category\" applying Classification regaring DWT. Function is defined right below\n",
    "panel_df[\"Category\"] = panel_df.apply(classify_vessel, axis=1)\n",
    "\n",
    "panel_df.head(25)  # show first 15 rows for quick check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21045074-2e1a-4db1-b9d7-0f938dc16089",
   "metadata": {},
   "source": [
    "### 6.3.1 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4fafb5-2afa-459e-81a7-b9a85481939e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DESCRIPTIVE STATISTICS of PANEL\n",
    "bulk_df = panel_df[panel_df[\"Ship type\"] == \"Bulk carrier\"]\n",
    "cont_df = panel_df[panel_df[\"Ship type\"] == \"Container ship\"]\n",
    "oil_df = panel_df[panel_df[\"Ship type\"] == \"Oil tanker\"]\n",
    "chem_df= panel_df[panel_df[\"Ship type\"] == \"Chemical tanker\"]\n",
    "\n",
    "\n",
    "vars_list=[\n",
    "        \"CO2 Eff.\",\n",
    "        \"TEI\",\n",
    "        \"Speed\",\n",
    "        \"Age\",\n",
    "        \"DWT\"\n",
    "    ]\n",
    "\n",
    "desc_stats = compute_descriptive_stats(\n",
    "    chem_df,\n",
    "    vars_list,\n",
    "    group_col=None,\n",
    "    #corr_ref=\"Technical efficiency Index Value [gCO₂/t·nm]\"  # optional\n",
    ")\n",
    "\n",
    "corr_matrix = chem_df[vars_list].corr(method='pearson')\n",
    "\n",
    "# Round and display nicely\n",
    "print(desc_stats.round(2).to_string(index=False))\n",
    "\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f6efa-fa36-40c1-8ee6-8af578a55e84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "### 6.3.2 Vessels per Category: Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d9903-dd1c-434c-b642-358e5068d9d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group by Ship type, Category, and Reporting Period, then count vessels\n",
    "counts = (\n",
    "    panel_df.groupby([\"Ship type\", \"Category\", \"Reporting Period\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"Count\")\n",
    ")\n",
    "# Define category order by DWT for each ship type\n",
    "bulk_order = [\n",
    "    \"Mini Bulk Carrier\", \"Handysize\", \"Handymax\", \"Supramax\",\n",
    "    \"Panamax\", \"Capesize\"\n",
    "]\n",
    "oil_order = [\n",
    "    \"Handysize\", \"MR1\", \"MR2\", \"Panamax\",\n",
    "    \"Aframax\", \"Suezmax\", \"VLCC\"\n",
    "]\n",
    "chem_order = [\n",
    "    \"Handysize\", \"MR1\", \"MR2\", \"LR1\", \"LR2\",\n",
    "    \"Suezmax\", \"VLCC\"\n",
    "]\n",
    "cont_order = [\n",
    "    \"Feeder\", \"Feedermax\", \"Panamax\", \"Post-Panamax\",\n",
    "    \"Neo-Panamax\", \"ULCV\"\n",
    "]\n",
    "# Function to generate pivot table with correct order\n",
    "def make_table(ship_type, category_order):\n",
    "    df_type = counts[counts[\"Ship type\"] == ship_type]\n",
    "    pivot = df_type.pivot_table(\n",
    "        index=\"Category\",\n",
    "        columns=\"Reporting Period\",\n",
    "        values=\"Count\",\n",
    "        fill_value=0\n",
    "    )\n",
    "    # Reorder rows\n",
    "    pivot = pivot.reindex(category_order)\n",
    "    return pivot\n",
    "# Create ordered tables\n",
    "bulk_table = make_table(\"Bulk carrier\", bulk_order)\n",
    "oil_table = make_table(\"Oil tanker\", oil_order)\n",
    "chem_table = make_table(\"Chemical tanker\", chem_order)\n",
    "cont_table = make_table(\"Container ship\", cont_order)\n",
    "\n",
    "# Example: show oil tankers\n",
    "oil_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80c5d9-8a86-4356-b912-dcfaaea64e49",
   "metadata": {},
   "source": [
    "### 6.3.3 Vessels per Category: Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8483c68-ce71-4369-9d93-7d874786dc11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#------Plot Bar Chart-----------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Generic filter function ---\n",
    "def filter_small_categories(table, threshold=5):\n",
    "    \"\"\"Remove categories with total vessel count < threshold.\"\"\"\n",
    "    totals = table.sum(axis=1)\n",
    "    keep = totals[totals >= threshold].index\n",
    "    return table.loc[keep]\n",
    "\n",
    "# Apply filtering to all ship types\n",
    "bulk_table_filt = filter_small_categories(bulk_table, threshold=5)\n",
    "oil_table_filt = filter_small_categories(oil_table, threshold=5)\n",
    "chem_table_filt = filter_small_categories(chem_table, threshold=5)\n",
    "cont_table_filt = filter_small_categories(cont_table, threshold=5)\n",
    "\n",
    "# --- Plotting: 4 subplots (one per ship type) ---\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "tables = [\n",
    "    (\"Bulk carrier\", bulk_table_filt),\n",
    "    (\"Oil tanker\", oil_table_filt),\n",
    "    (\"Chemical tanker\", chem_table_filt),\n",
    "    (\"Container ship\", cont_table_filt)\n",
    "]\n",
    "\n",
    "for ax, (title, table) in zip(axes, tables):\n",
    "    if table is None or table.shape[0] == 0 or table.shape[1] == 0:\n",
    "        ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=12)\n",
    "        ax.set_title(title, fontsize=16, fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Reporting Year\", fontsize=14)\n",
    "        ax.set_ylabel(\"Number of Vessels\", fontsize=14)\n",
    "        continue\n",
    "\n",
    "    years = list(table.columns.astype(str))\n",
    "    categories = list(table.index)\n",
    "\n",
    "    n_years = len(years)\n",
    "    n_cat = len(categories)\n",
    "\n",
    "    x = np.arange(n_years)\n",
    "    total_group_width = 0.8\n",
    "    bar_width = total_group_width / max(n_cat, 1)\n",
    "\n",
    "    for i, cat in enumerate(categories):\n",
    "        vals = table.loc[cat].reindex(table.columns, fill_value=0).values\n",
    "        shift = (i - (n_cat - 1) / 2) * bar_width\n",
    "        ax.bar(x + shift, vals, width=bar_width, label=cat)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(years, rotation=45, ha='right')\n",
    "    ax.set_title(title, fontsize=18, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Reporting Year\", fontsize=14)\n",
    "    ax.set_ylabel(\"Number of Vessels\", fontsize=14)\n",
    "\n",
    "    # Legend with bold title and larger font\n",
    "    leg = ax.legend(\n",
    "        title=\"Category\", \n",
    "        bbox_to_anchor=(1.02, 1), \n",
    "        loc='upper left', \n",
    "        fontsize=15,             # <--- Increased font size here\n",
    "        title_fontsize=16        # <--- Bold title with slightly larger size\n",
    "    )\n",
    "    plt.setp(leg.get_title(), fontweight=\"bold\")\n",
    "\n",
    "# Add a main title for the whole figure\n",
    "fig.suptitle(\"Categories of Main Ship Types\", fontsize=25, fontweight=\"bold\", y=0.98)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to make space for main title\n",
    "\n",
    "# Save to your folder\n",
    "output_filename = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\\Panel_ship_categories_by_year.svg\"\n",
    "fig.savefig(output_filename, format=\"svg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "print(f\"Saved SVG to: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce11bf2-bfe8-497e-9083-ccad18cf49f6",
   "metadata": {},
   "source": [
    "# 7 Panel Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd8650-0912-4394-8dde-d65644b960ca",
   "metadata": {},
   "source": [
    "## 7.1 Check Stationarity (a) - Export to R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd86914-6dd3-4d4a-a0f4-22e472f9afdc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bulk_panel = panel_df[panel_df['Ship type'] == 'Bulk carrier'].copy()\n",
    "bulk_panel = bulk_panel.drop(columns=[\"Name\"])\n",
    "bulk_panel = bulk_panel.drop(columns=[\"Ship type\"])\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def fisher_panel_unit_root(df, entity_col, value_col, min_obs=3, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Fisher-type panel unit root test (Maddala & Wu, 1999).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Panel dataset\n",
    "    entity_col : str\n",
    "        Column with cross-section ID (e.g. 'IMO Number')\n",
    "    value_col : str\n",
    "        Column with series values (e.g. 'CO2 Eff.')\n",
    "    min_obs : int\n",
    "        Minimum number of non-NA observations per entity\n",
    "    eps : float\n",
    "        Floor for p-values to avoid log(0)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict with test statistic, p-value, and sample info\n",
    "    \"\"\"\n",
    "    pvals = []\n",
    "    \n",
    "    for entity, group in df.groupby(entity_col):\n",
    "        series = group[value_col].dropna()\n",
    "        if len(series) >= min_obs and series.nunique() > 1:\n",
    "            try:\n",
    "                res = adfuller(series, maxlag=1, regression=\"c\", autolag=None)  # drift + 1 lag\n",
    "                p = max(res[1], eps)  # clip p-value\n",
    "                pvals.append(p)\n",
    "            except Exception:\n",
    "                continue\n",
    "    \n",
    "    N = len(pvals)\n",
    "    if N == 0:\n",
    "        return {\"Variable\": value_col, \"Chi2\": np.nan, \"df\": np.nan,\n",
    "                \"p_value\": np.nan, \"N_used\": 0}\n",
    "    \n",
    "    chi2_stat = -2 * np.sum(np.log(pvals))\n",
    "    p_value = chi2.sf(chi2_stat, 2*N)\n",
    "    \n",
    "    return {\"Variable\": value_col,\n",
    "            \"Chi2\": chi2_stat,\n",
    "            \"df\": 2*N,\n",
    "            \"p_value\": p_value,\n",
    "            \"N_used\": N}\n",
    "\n",
    "# === Example usage ===\n",
    "variables = [\"CO2 Eff.\", \"TEI\", \"Speed\"]\n",
    "results = []\n",
    "\n",
    "for var in variables:\n",
    "    results.append(fisher_panel_unit_root(bulk_panel, entity_col=\"IMO Number\", value_col=var))\n",
    "\n",
    "summary = pd.DataFrame(results)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc21d9-17ae-4068-b500-6bc0a7d04923",
   "metadata": {},
   "source": [
    "## 7.1 Check Stationarity (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234da832-0684-4a89-89a1-366dca01d60e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy import stats\n",
    "\n",
    "def ips_panel_adf(df, entity_col, value_col, min_obs=4):\n",
    "    \"\"\"\n",
    "    Simple IPS-style panel ADF test (Im, Pesaran & Shin 2003).\n",
    "    Computes the average of ADF tau-statistics across entities.\n",
    "    \"\"\"\n",
    "    tau_list = []\n",
    "\n",
    "    for entity, group in df.groupby(entity_col):\n",
    "        series = group[value_col].dropna()\n",
    "        if len(series) >= min_obs and series.nunique() > 1:\n",
    "            try:\n",
    "                result = adfuller(series, regression=\"c\", autolag=\"AIC\")\n",
    "                tau_stat = result[0]   # ADF test statistic\n",
    "                tau_list.append(tau_stat)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if not tau_list:\n",
    "        return {\"Variable\": value_col, \"Mean_tau\": np.nan, \"p_value\": np.nan, \"N_used\": 0}\n",
    "\n",
    "    tau_avg = np.mean(tau_list)\n",
    "    N = len(tau_list)\n",
    "\n",
    "    # Two-sided t-test (approximation)\n",
    "    p_value = 2 * stats.t.sf(abs(tau_avg), df=N-1)\n",
    "\n",
    "    return {\"Variable\": value_col, \"Mean_tau\": tau_avg, \"p_value\": p_value, \"N_used\": N}\n",
    "\n",
    "# === Example Usage ===\n",
    "variables = [\"CO2 Eff.\", \"Speed\"]\n",
    "results = []\n",
    "\n",
    "for var in variables:\n",
    "    results.append(ips_panel_adf(panel_df, entity_col=\"IMO Number\", value_col=var))\n",
    "\n",
    "summary = pd.DataFrame(results)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de055b2-bd5b-48bb-816e-4addd9c70449",
   "metadata": {},
   "source": [
    "## 7.2 --- All 4 Categories Models ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3c396-abf2-41e6-b87f-4797e0c3ad92",
   "metadata": {},
   "source": [
    "### 7.2.8 CRE Model with Dummy Years and Types and Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7536d-3b7f-4f85-ad8a-1e6c18728fb5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------- ORIGINA MODEL --------- #\n",
    "\n",
    "import pandas as pd\n",
    "from linearmodels.panel import RandomEffects\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "df = panel_df.copy()\n",
    "df.columns = (df.columns\n",
    "                .str.strip()\n",
    "                .str.replace(\" \", \"_\")\n",
    "                .str.replace(r\"\\.\", \"\", regex=True))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) MultiIndex: vessel × year\n",
    "# -----------------------------\n",
    "df_cre = df.set_index(['IMO_Number','Reporting_Period']).copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Mundlak means for time-varying vars\n",
    "# -----------------------------\n",
    "time_varying = ['Speed','Age']\n",
    "means = df_cre.groupby(level=0)[time_varying].transform('mean').add_suffix('_mean')\n",
    "df_cre = df_cre.join(means)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Year dummies\n",
    "# -----------------------------\n",
    "years = df_cre.index.get_level_values('Reporting_Period')\n",
    "year_dummies = pd.get_dummies(years, prefix=\"year\", drop_first=True)\n",
    "year_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(year_dummies)\n",
    "year_terms = \" + \".join(year_dummies.columns)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Ship-type dummies (baseline = Bulk carrier)\n",
    "# -----------------------------\n",
    "ship_dummies = pd.get_dummies(df_cre['Ship_type'], drop_first=True)\n",
    "\n",
    "# sanitize column names\n",
    "ship_dummies.columns = (ship_dummies.columns\n",
    "                        .str.strip()\n",
    "                        .str.replace(r'\\s+', '_', regex=True)\n",
    "                        .str.replace(r'\\W+', '', regex=True))\n",
    "\n",
    "ship_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(ship_dummies)\n",
    "ship_terms = \" + \".join(ship_dummies.columns)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Interactions: Ship type × Year\n",
    "# -----------------------------\n",
    "interaction_terms = []\n",
    "for ship in ship_dummies.columns:\n",
    "    for year in year_dummies.columns:\n",
    "        inter_name = f\"{ship}_x_{year}\"\n",
    "        df_cre[inter_name] = df_cre[ship] * df_cre[year]\n",
    "        interaction_terms.append(inter_name)\n",
    "\n",
    "interaction_str = \" + \".join(interaction_terms)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Build formula\n",
    "# -----------------------------\n",
    "formula = (\n",
    "    \"CO2_Eff ~ 1 + \"\n",
    "    \"Speed + Age \"                 # within-ship effects\n",
    "    \"+ Speed_mean + Age_mean \"     # between-vessel averages\n",
    "    \"+ TEI + DWT \"                 # time-invariant vessel-level regressors\n",
    "    f\"+ {year_terms} \"             # year dummies\n",
    "    f\"+ {ship_terms} \"             # ship-type dummies\n",
    "    f\"+ {interaction_str}\"         # ship-type × year interactions\n",
    ")\n",
    "\n",
    "print(\"Using formula:\\n\", formula, \"\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Fit CRE model\n",
    "# -----------------------------\n",
    "cre_model = RandomEffects.from_formula(formula, data=df_cre)\n",
    "cre_res = cre_model.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(cre_res.summary)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Mundlak joint test (means)\n",
    "# -----------------------------\n",
    "mean_vars = ['Speed_mean','Age_mean']\n",
    "beta = cre_res.params[mean_vars].values\n",
    "V = cre_res.cov.loc[mean_vars, mean_vars].values\n",
    "wald = float(beta.T @ np.linalg.inv(V) @ beta)\n",
    "pval = chi2.sf(wald, len(mean_vars))\n",
    "print(\"\\nMundlak test χ²:\", wald, \" p-value:\", pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b672160-20bf-4a19-95f9-54853a319a78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- VIF Diagnostics for Panel Model --- #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# 1️⃣ Build the design matrix (X) from the same df_cre used in your regression\n",
    "X = df_cre.copy().drop(columns=[\"CO2_Eff\"], errors=\"ignore\")\n",
    "\n",
    "# Only keep numeric variables\n",
    "X = X.select_dtypes(include=[np.number]).fillna(0)\n",
    "\n",
    "# Add constant (intercept) for VIF calculation\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# 2️⃣ Compute VIF for all variables\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# 3️⃣ Identify continuous vs. dummy variables\n",
    "continuous_vars = [\"Speed\", \"Age\", \"Speed_mean\", \"Age_mean\", \"TEI\", \"DWT\"]  # edit if needed\n",
    "\n",
    "def classify_var(name):\n",
    "    if name in continuous_vars:\n",
    "        return \"Continuous\"\n",
    "    elif name == \"const\":\n",
    "        return \"Constant\"\n",
    "    else:\n",
    "        return \"Dummy/Interaction\"\n",
    "\n",
    "vif_data[\"Type\"] = vif_data[\"feature\"].apply(classify_var)\n",
    "\n",
    "# 4️⃣ Sort by VIF and show top 10\n",
    "vif_top10 = vif_data.sort_values(\"VIF\", ascending=False).head(10)\n",
    "\n",
    "print(\"\\n📊 Top 10 Variables by VIF:\\n\")\n",
    "print(vif_top10.to_string(index=False))\n",
    "\n",
    "# Optional: export full VIF table\n",
    "vif_data_sorted = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "vif_data_sorted.to_csv(\"vif_results.csv\", index=False)\n",
    "print(\"\\n✅ Full VIF table saved as 'vif_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f533c-5c6b-4ef9-be43-81b8af6035f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--- SPEED SQUARE AND CENTERED -------#\n",
    "# --- further caluclations on SE of Speed ------#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from linearmodels.panel import RandomEffects\n",
    "\n",
    "# === 1. Prepare panel data ===\n",
    "df = panel_df.copy()\n",
    "df.columns = (df.columns\n",
    "              .str.strip()\n",
    "              .str.replace(\" \", \"_\")\n",
    "              .str.replace(r\"\\.\", \"\", regex=True))\n",
    "df_cre = df.set_index(['IMO_Number', 'Reporting_Period']).copy()\n",
    "\n",
    "# === 2. Mundlak means for time-varying vars ===\n",
    "time_varying = ['Speed', 'Age']\n",
    "means = df_cre.groupby(level=0)[time_varying].transform('mean').add_suffix('_mean')\n",
    "df_cre = df_cre.join(means)\n",
    "\n",
    "# === 3. Center speed and create squared term ===\n",
    "mean_speed = df_cre['Speed'].mean()\n",
    "df_cre['Speed_c'] = df_cre['Speed'] - mean_speed\n",
    "df_cre['Speed_c_sq'] = df_cre['Speed_c'] ** 2\n",
    "\n",
    "# Add between-vessel averages (Mundlak)\n",
    "df_cre['Speed_c_mean'] = df_cre.groupby(level=0)['Speed_c'].transform('mean')\n",
    "df_cre['Speed_c_sq_mean'] = df_cre.groupby(level=0)['Speed_c_sq'].transform('mean')\n",
    "\n",
    "# === 4. Year dummies ===\n",
    "years = df_cre.index.get_level_values('Reporting_Period')\n",
    "year_dummies = pd.get_dummies(years, prefix=\"year\", drop_first=True)\n",
    "year_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(year_dummies)\n",
    "year_terms = \" + \".join(year_dummies.columns)\n",
    "\n",
    "# === 5. Ship-type dummies ===\n",
    "ship_dummies = pd.get_dummies(df_cre['Ship_type'], drop_first=True)\n",
    "ship_dummies.columns = (ship_dummies.columns\n",
    "                        .str.strip()\n",
    "                        .str.replace(r'\\s+', '_', regex=True)\n",
    "                        .str.replace(r'\\W+', '', regex=True))\n",
    "ship_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(ship_dummies)\n",
    "ship_terms = \" + \".join(ship_dummies.columns)\n",
    "\n",
    "# === 6. Interaction terms ===\n",
    "interaction_terms = []\n",
    "for ship in ship_dummies.columns:\n",
    "    for year in year_dummies.columns:\n",
    "        inter_name = f\"{ship}_x_{year}\"\n",
    "        df_cre[inter_name] = df_cre[ship] * df_cre[year]\n",
    "        interaction_terms.append(inter_name)\n",
    "interaction_str = \" + \".join(interaction_terms)\n",
    "\n",
    "# === 7. Build and fit CRE model ===\n",
    "formula = (\n",
    "    \"CO2_Eff ~ 1 + \"\n",
    "    \"Speed_c + Speed_c_sq + Age \"\n",
    "    \"+ Speed_c_mean + Speed_c_sq_mean + Age_mean \"\n",
    "    \"+ TEI + DWT \"\n",
    "    f\"+ {year_terms} + {ship_terms} + {interaction_str}\"\n",
    ")\n",
    "\n",
    "cre_model = RandomEffects.from_formula(formula, data=df_cre)\n",
    "cre_res = cre_model.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(cre_res.summary)\n",
    "\n",
    "# === 8. Compute turning point and its 95% CI (delta method) ===\n",
    "b1 = cre_res.params['Speed_c']\n",
    "b2 = cre_res.params['Speed_c_sq']\n",
    "cov_b1b2 = cre_res.cov.loc['Speed_c', 'Speed_c_sq']\n",
    "var_b1 = cre_res.cov.loc['Speed_c', 'Speed_c']\n",
    "var_b2 = cre_res.cov.loc['Speed_c_sq', 'Speed_c_sq']\n",
    "\n",
    "# Turning point\n",
    "speed_star = -b1 / (2 * b2) + mean_speed\n",
    "\n",
    "# Delta method variance\n",
    "d_b1 = -1 / (2 * b2)\n",
    "d_b2 = b1 / (2 * (b2 ** 2))\n",
    "var_speed_star = (d_b1 ** 2) * var_b1 + (d_b2 ** 2) * var_b2 + 2 * d_b1 * d_b2 * cov_b1b2\n",
    "se_speed_star = np.sqrt(var_speed_star)\n",
    "\n",
    "# 95% CI for turning point\n",
    "ci_lower = float(speed_star - 1.96 * se_speed_star)\n",
    "ci_upper = float(speed_star + 1.96 * se_speed_star)\n",
    "\n",
    "print(f\"Turning point: {speed_star:.2f} kn\")\n",
    "print(f\"95% CI for turning point: [{ci_lower:.2f}, {ci_upper:.2f}] kn\")\n",
    "\n",
    "# 1) Overall mean of continuous variables\n",
    "controls = ['Age', 'Speed_c_mean', 'Speed_c_sq_mean', 'Age_mean', 'TEI', 'DWT']\n",
    "C_controls = sum(cre_res.params[v] * df_cre[v].mean() for v in controls if v in cre_res.params.index)\n",
    "\n",
    "# 2) Mean of year effects\n",
    "year_coef_names = [c for c in cre_res.params.index if c.startswith('year_')]\n",
    "C_year = float(np.mean(cre_res.params[year_coef_names])) if year_coef_names else 0.0\n",
    "\n",
    "# 3) Mean of ship-type effects\n",
    "ship_coef_names = [c for c in ship_dummies.columns if c in cre_res.params.index]\n",
    "C_ship = float(np.mean(cre_res.params[ship_coef_names])) if ship_coef_names else 0.0\n",
    "\n",
    "# Final constant shift (no interaction effects)\n",
    "C = C_controls + C_year + C_ship\n",
    "\n",
    "# === 9. Build prediction curve and confidence bands ===\n",
    "speeds = np.linspace(8, 17, 300)\n",
    "sc = speeds - mean_speed\n",
    "\n",
    "mu = (cre_res.params['Intercept'] +\n",
    "      cre_res.params['Speed_c'] * sc +\n",
    "      cre_res.params['Speed_c_sq'] * sc**2\n",
    "     +C)\n",
    "\n",
    "# Covariance matrix for prediction\n",
    "cov = cre_res.cov.loc[['Intercept', 'Speed_c', 'Speed_c_sq'],\n",
    "                      ['Intercept', 'Speed_c', 'Speed_c_sq']].values\n",
    "X = np.vstack([np.ones_like(sc), sc, sc**2]).T\n",
    "se = np.sqrt(np.sum(X @ cov * X, axis=1))\n",
    "\n",
    "upper = mu + 1.96 * se\n",
    "lower = mu - 1.96 * se\n",
    "\n",
    "# Minima of upper/lower bands\n",
    "idx_lo = np.argmin(lower)\n",
    "idx_hi = np.argmin(upper)\n",
    "x_lo, x_hi = speeds[idx_lo], speeds[idx_hi]\n",
    "print(f\"Argmin of lower band: {x_lo:.2f} kn\")\n",
    "print(f\"Argmin of upper band: {x_hi:.2f} kn\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "\n",
    "# --- Global font: Times New Roman ---\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# === 10. Plot results ===\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "# Prediction curve and confidence band\n",
    "ax.plot(speeds, mu, color=\"firebrick\", linewidth=2, label=\"Fitted CO₂ Efficiency\")\n",
    "ax.fill_between(speeds, lower, upper, color=\"firebrick\", alpha=0.2, label=\"95% CI of CO₂ Efficiency\")\n",
    "\n",
    "# Vertical line at turning point\n",
    "ax.axvline(speed_star, color=\"gray\", linestyle=\"--\", linewidth=1.5, label=f\"Optimal Speed ≈ {speed_star:.2f} kn\")\n",
    "\n",
    "# ✅ New: vertical lines for CI boundaries\n",
    "ax.axvline(ci_lower, color=\"gray\", linestyle=\":\", linewidth=1.2, label=f\"Lower CI ≈ {ci_lower:.2f} kn\")\n",
    "ax.axvline(ci_upper, color=\"gray\", linestyle=\":\", linewidth=1.2, label=f\"Upper CI ≈ {ci_upper:.2f} kn\")\n",
    "\n",
    "# Shaded region showing turning point CI\n",
    "ax.axvspan(ci_lower, ci_upper, color=\"gray\", alpha=0.15, label=\"95% CI of Optimal Speed\")\n",
    "\n",
    "# Annotate turning point (mean curve)\n",
    "eff_star = (cre_res.params['Intercept'] +\n",
    "            cre_res.params['Speed_c'] * (speed_star - mean_speed) +\n",
    "            cre_res.params['Speed_c_sq'] * (speed_star - mean_speed)**2 + C)\n",
    "ax.scatter(speed_star, eff_star, color=\"black\", s=70, zorder=5, label=\"Turning Point\")\n",
    "ax.text(speed_star + 0.1, eff_star, f\"{speed_star:.2f} kn\", fontsize=12, va=\"bottom\")\n",
    "\n",
    "# === NEW: Show minima of upper and lower bands ===\n",
    "eff_lo = lower[idx_lo]\n",
    "eff_hi = upper[idx_hi]\n",
    "ax.scatter(x_lo, eff_lo, color=\"blue\", s=70, zorder=5, marker='o', label=\"Min Lower Band\")\n",
    "ax.scatter(x_hi, eff_hi, color=\"green\", s=70, zorder=5, marker='o', label=\"Min Upper Band\")\n",
    "\n",
    "# Annotate them\n",
    "ax.text(x_lo + 0.1, eff_lo, f\"{x_lo:.2f} kn\", fontsize=12, color=\"blue\", va=\"bottom\")\n",
    "ax.text(x_hi + 0.1, eff_hi, f\"{x_hi:.2f} kn\", fontsize=12, color=\"green\", va=\"bottom\")\n",
    "\n",
    "# === Annotate CI bounds on x-axis ===\n",
    "y_min_for_text = ax.get_ylim()[0] - 0.1  # just below x-axis\n",
    "ax.text(ci_lower, y_min_for_text, f\"{ci_lower:.2f} kn\", fontsize=11, ha=\"center\", va=\"top\", color=\"gray\")\n",
    "ax.text(ci_upper, y_min_for_text, f\"{ci_upper:.2f} kn\", fontsize=11, ha=\"center\", va=\"top\", color=\"gray\")\n",
    "\n",
    "# === X-axis improvements ===\n",
    "ax.set_xticks(np.arange(8, 18, 1))  # tick every 1 knot\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Labels and aesthetics\n",
    "ax.set_xlabel(\"Speed [knots]\", fontsize=14)\n",
    "ax.set_ylabel(\"Estimated CO₂ Efficiency [gCO₂/t·nm]\", fontsize=14)\n",
    "ax.set_title(\"U-Shaped Relationship Between Speed and CO₂ Efficiency\\n(Centered Quadratic)\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "# ✅ Start y-axis from 3\n",
    "ymax = np.max(upper) * 1.05  # small padding above\n",
    "ax.set_ylim(2+C, ymax)\n",
    "\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "# Legend inside top-right\n",
    "ax.legend(loc='lower right', fontsize=10, frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# === Save figure ===\n",
    "save_path = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\\speed_curves.svg\"\n",
    "plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Figure saved successfully to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5f29e-8556-4405-8a49-447d5d6ddfc1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- FUNCTION FOR EXPORTING TABLES ----#\n",
    "import pandas as pd\n",
    "\n",
    "def export_cre_results(model_result, model_name, save_dir=None):\n",
    "    \"\"\"\n",
    "    Extracts, cleans, and exports RandomEffects model results\n",
    "    into a thesis-style regression table (like your screenshots).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_result : linearmodels RandomEffectsResults\n",
    "        The fitted model result object (e.g., cre_res)\n",
    "    model_name : str\n",
    "        Short name for the model (used for filename and sheet name)\n",
    "    save_dir : str, optional\n",
    "        Directory to save the Excel file (if None, table only prints)\n",
    "    \"\"\"\n",
    "\n",
    "    # === Extract basic results ===\n",
    "    df = pd.DataFrame({\n",
    "        \"Variable\": model_result.params.index,\n",
    "        \"Estimate\": model_result.params.values,\n",
    "        \"Std. Err.\": model_result.std_errors.values,\n",
    "        \"t-stat\": model_result.tstats.values,\n",
    "        \"p-value\": model_result.pvalues.values,\n",
    "        \"95% CI (Lower)\": model_result.conf_int().iloc[:, 0].values,\n",
    "        \"95% CI (Upper)\": model_result.conf_int().iloc[:, 1].values\n",
    "    })\n",
    "\n",
    "    # === Clean up variable names ===\n",
    "    df[\"Variable\"] = (\n",
    "        df[\"Variable\"]\n",
    "        .replace({\n",
    "            \"Speed_c_sq\": \"(Speed_c)²\",\n",
    "            \"log_Speed\": \"ln(Speed)\",\n",
    "            \"log_CO2_Eff\": \"ln(CO₂ Efficiency)\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # === Filter out intercepts and interaction terms ===\n",
    "    df = df[~df[\"Variable\"].str.contains(\"Intercept|_x_\")].reset_index(drop=True)\n",
    "\n",
    "    # === Formatting ===\n",
    "    df[\"Estimate\"] = df[\"Estimate\"].round(4)\n",
    "    df[\"Std. Err.\"] = df[\"Std. Err.\"].round(4)\n",
    "    df[\"t-stat\"] = df[\"t-stat\"].round(4)\n",
    "    df[\"95% CI (Lower)\"] = df[\"95% CI (Lower)\"].round(4)\n",
    "    df[\"95% CI (Upper)\"] = df[\"95% CI (Upper)\"].round(4)\n",
    "    df[\"p-value\"] = df[\"p-value\"].apply(lambda p: \"<0.001\" if p < 0.001 else round(p, 4))\n",
    "\n",
    "    # === Display formatted table ===\n",
    "    print(f\"\\n=== Formatted Results: {model_name} ===\")\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    # === Optional: export to Excel ===\n",
    "    if save_dir:\n",
    "        save_path = f\"{save_dir}/{model_name}_results.xlsx\"\n",
    "        df.to_excel(save_path, index=False)\n",
    "        print(f\"\\n✅ Table saved to: {save_path}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc144b7-b975-468c-8f5b-675fd10da6e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -- export results --- #\n",
    "save_dir = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Tables\"\n",
    "\n",
    "table = export_cre_results(cre_res, \"Full_Model_Speed\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabeeab-60ed-4d47-b460-62f3b5b2c672",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Quadratic log(TEI) model with CRE and dual visualization (all ship types, realistic predictions) --- #\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from linearmodels.panel import RandomEffects\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# === 1. Prepare panel data ===\n",
    "df = panel_df.copy()\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(r\"\\.\", \"\", regex=True)\n",
    ")\n",
    "df_cre = df.set_index(['IMO_Number', 'Reporting_Period']).copy()\n",
    "\n",
    "# === 2. Log-transform variables ===\n",
    "df_cre['log_CO2_Eff'] = np.log(df_cre['CO2_Eff'])\n",
    "df_cre['log_Speed'] = np.log(df_cre['Speed'])\n",
    "df_cre['log_TEI'] = np.log(df_cre['TEI'])\n",
    "df_cre['log_DWT'] = np.log(df_cre['DWT'])\n",
    "\n",
    "# === 3. Mundlak means ===\n",
    "time_varying_log = ['log_Speed', 'Age']\n",
    "means_log = df_cre.groupby(level=0)[time_varying_log].transform('mean').add_suffix('_mean')\n",
    "df_cre = df_cre.join(means_log)\n",
    "\n",
    "# === 4. Quadratic term ===\n",
    "df_cre['log_TEI_sq'] = df_cre['log_TEI'] ** 2\n",
    "\n",
    "# === 5. Year dummies ===\n",
    "years = df_cre.index.get_level_values('Reporting_Period')\n",
    "year_dummies = pd.get_dummies(years, prefix=\"year\", drop_first=True)\n",
    "year_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(year_dummies)\n",
    "year_terms = \" + \".join(year_dummies.columns)\n",
    "\n",
    "# === 6. Ship-type dummies ===\n",
    "ship_dummies = pd.get_dummies(df_cre['Ship_type'], drop_first=True)\n",
    "ship_dummies.columns = (\n",
    "    ship_dummies.columns\n",
    "    .str.strip()\n",
    "    .str.replace(r'\\s+', '_', regex=True)\n",
    "    .str.replace(r'\\W+', '', regex=True)\n",
    ")\n",
    "ship_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(ship_dummies)\n",
    "ship_terms = \" + \".join(ship_dummies.columns)\n",
    "\n",
    "# === 7. Interactions ===\n",
    "interaction_terms = []\n",
    "for ship in ship_dummies.columns:\n",
    "    for year in year_dummies.columns:\n",
    "        inter_name = f\"{ship}_x_{year}\"\n",
    "        df_cre[inter_name] = df_cre[ship] * df_cre[year]\n",
    "        interaction_terms.append(inter_name)\n",
    "interaction_str = \" + \".join(interaction_terms)\n",
    "\n",
    "# === 8. Fit the CRE model ===\n",
    "formula_nl = (\n",
    "    \"log_CO2_Eff ~ 1 + \"\n",
    "    \"log_Speed + Age + log_TEI + log_TEI_sq + log_DWT \"\n",
    "    \"+ log_Speed_mean + Age_mean \"\n",
    "    f\"+ {year_terms} + {ship_terms} + {interaction_str}\"\n",
    ")\n",
    "cre_model_nl = RandomEffects.from_formula(formula_nl, data=df_cre)\n",
    "cre_res_nl = cre_model_nl.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(cre_res_nl.summary)\n",
    "\n",
    "# === 9. Extract coefficients ===\n",
    "params = cre_res_nl.params\n",
    "b0 = params['Intercept']\n",
    "b1 = params['log_TEI']\n",
    "b2 = params['log_TEI_sq']\n",
    "\n",
    "# === 10. Compute means for other variables ===\n",
    "mean_log_speed = df_cre['log_Speed'].mean()\n",
    "mean_age = df_cre['Age'].mean()\n",
    "mean_log_dwt = df_cre['log_DWT'].mean()\n",
    "mean_log_speed_mean = df_cre['log_Speed_mean'].mean()\n",
    "mean_age_mean = df_cre['Age_mean'].mean()\n",
    "\n",
    "# === 11. Define TEI range ===\n",
    "log_tei_range = np.linspace(df_cre['log_TEI'].quantile(0.05), df_cre['log_TEI'].quantile(0.95), 200)\n",
    "tei_range = np.exp(log_tei_range)\n",
    "\n",
    "# === 12. Marginal elasticity ===\n",
    "var_b1 = cre_res_nl.cov.loc['log_TEI', 'log_TEI']\n",
    "var_b2 = cre_res_nl.cov.loc['log_TEI_sq', 'log_TEI_sq']\n",
    "cov_b1b2 = cre_res_nl.cov.loc['log_TEI', 'log_TEI_sq']\n",
    "\n",
    "elasticity = b1 + 2 * b2 * log_tei_range\n",
    "se_elasticity = np.sqrt(\n",
    "    var_b1 + (2 * log_tei_range) ** 2 * var_b2 + 2 * (2 * log_tei_range) * cov_b1b2\n",
    ")\n",
    "upper_el = elasticity + 1.96 * se_elasticity\n",
    "lower_el = elasticity - 1.96 * se_elasticity\n",
    "\n",
    "# === 13. Predict CO₂ efficiency (holding other vars at means) ===\n",
    "log_pred = (\n",
    "    b0\n",
    "    + b1 * log_tei_range\n",
    "    + b2 * log_tei_range ** 2\n",
    "    + params['log_Speed'] * mean_log_speed\n",
    "    + params['Age'] * mean_age\n",
    "    + params['log_DWT'] * mean_log_dwt\n",
    "    + params['log_Speed_mean'] * mean_log_speed_mean\n",
    "    + params['Age_mean'] * mean_age_mean\n",
    ")\n",
    "predicted_eff = np.exp(log_pred)\n",
    "\n",
    "# === 14. Plot both subplots ===\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# --- (A) Elasticity ---\n",
    "axes[0].plot(log_tei_range, elasticity, color=\"firebrick\", linewidth=2, label=\"Elasticity\")\n",
    "axes[0].fill_between(log_tei_range, lower_el, upper_el, color=\"firebrick\", alpha=0.2, label=\"95% CI\")\n",
    "axes[0].axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "axes[0].set_xlabel(\"log(TEI)\", fontsize=14, labelpad=3)  # ↓ label closer\n",
    "axes[0].set_ylabel(\"Marginal Elasticity of CO₂ Efficiency\", fontsize=14, labelpad=6)  # ↓ closer\n",
    "axes[0].set_title(\"(A) Elasticity Curve (Log–Log Model)\", fontsize=15, fontweight=\"bold\", pad=10)\n",
    "axes[0].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "axes[0].legend(fontsize=11, loc='best')\n",
    "\n",
    "# --- (B) Natural Scale Predictions ---\n",
    "axes[1].plot(tei_range, predicted_eff, color=\"navy\", linewidth=2, label=\"Predicted CO₂ Efficiency\")\n",
    "axes[1].set_xlabel(\"TEI\", fontsize=14, labelpad=1)  # ↓ closer\n",
    "axes[1].set_ylabel(\"Predicted CO₂ Efficiency [gCO₂/t·nm]\", fontsize=14, labelpad=6)\n",
    "axes[1].set_title(\"(B) Predicted CO₂ Efficiency vs TEI (Natural Scale)\", fontsize=15, fontweight=\"bold\", pad=10)\n",
    "axes[1].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "axes[1].legend(fontsize=11, loc='best')\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Elasticity vs. Natural Relationship of TEI and CO₂ Efficiency (Main Ships)\",\n",
    "    fontsize=19,\n",
    "    fontweight=\"bold\",\n",
    "    y=1.015  # ↓ Moves the title closer to the subplots (default is ≈ 0.98–0.99)\n",
    ")\n",
    "\n",
    "# === 15. Save figure ===\n",
    "save_path = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\\tei_elasticity_vs_levels_all_fixed.svg\"\n",
    "plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Figure saved successfully to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad6634-2445-4fb0-b7ea-92417ee4fc89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export results\n",
    "table = export_cre_results(cre_res_nl, \"All_Model_Log\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd1d3f-5ac0-4a72-90e7-20ee179dcd86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- plotting interactions Main Types ----#\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Folder to save ===\n",
    "fig_dir = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\"\n",
    "\n",
    "# ----- Inputs from your fitted model -----\n",
    "params = cre_res.params\n",
    "cov    = cre_res.cov\n",
    "\n",
    "# ===== COMMON SETUP =====\n",
    "year_cols = [c for c in params.index if c.startswith(\"year_\")]\n",
    "years = [2018] + sorted(int(c.split(\"_\")[1]) for c in year_cols)\n",
    "\n",
    "color_map = {\n",
    "    \"Bulk carrier\": \"steelblue\",\n",
    "    \"Oil tanker\": \"firebrick\",\n",
    "    \"Chemical tanker\": \"seagreen\",\n",
    "    \"Container ship\": \"darkorange\",\n",
    "}\n",
    "\n",
    "display_to_sanitized = {\n",
    "    \"Bulk carrier\": \"Bulk_carrier\",   # baseline (no dummy)\n",
    "    \"Oil tanker\": \"Oil_tanker\",\n",
    "    \"Chemical tanker\": \"Chemical_tanker\",\n",
    "    \"Container ship\": \"Container_ship\",\n",
    "}\n",
    "sanitized_to_display = {v: k for k, v in display_to_sanitized.items()}\n",
    "\n",
    "panel_order = [\"Bulk carrier\", \"Oil tanker\", \"Chemical tanker\", \"Container ship\"]\n",
    "legend_order = panel_order\n",
    "\n",
    "# ----- Helper: linear combination -----\n",
    "def lincomb(varnames):\n",
    "    a = np.zeros(len(params))\n",
    "    any_hit = False\n",
    "    for v in varnames:\n",
    "        if v in params.index:\n",
    "            a[params.index.get_loc(v)] += 1.0\n",
    "            any_hit = True\n",
    "    est = float(a @ params.values) if any_hit else 0.0\n",
    "    se  = float(np.sqrt(a @ cov.values @ a)) if any_hit else 0.0\n",
    "    return est, se\n",
    "\n",
    "# =========================================================\n",
    "# FIGURE 1: Within-type change relative to own 2018 baseline\n",
    "# =========================================================\n",
    "def build_series_for_category(display_name):\n",
    "    san = display_to_sanitized[display_name]\n",
    "    rows = []\n",
    "    for y in years:\n",
    "        if display_name == \"Bulk carrier\":\n",
    "            # Δ_t = λ_t\n",
    "            est, se = (0.0, 0.0) if y == 2018 else lincomb([f\"year_{y}\"])\n",
    "        else:\n",
    "            # Δ_t = λ_t + ψ_{c,t}\n",
    "            if y == 2018:\n",
    "                est, se = 0.0, 0.0\n",
    "            else:\n",
    "                terms = [f\"year_{y}\"]\n",
    "                inter = f\"{san}_x_year_{y}\"\n",
    "                if inter in params.index:\n",
    "                    terms.append(inter)\n",
    "                est, se = lincomb(terms)\n",
    "        rows.append({\"Year\": y, \"Estimate\": est, \"SE\": se})\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"lo\"] = df[\"Estimate\"] - 1.96 * df[\"SE\"]\n",
    "    df[\"hi\"] = df[\"Estimate\"] + 1.96 * df[\"SE\"]\n",
    "    return df\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(9, 6), sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, disp in zip(axes, panel_order):\n",
    "    dfp = build_series_for_category(disp)\n",
    "    ax.plot(dfp[\"Year\"], dfp[\"Estimate\"], marker=\"o\", color=color_map[disp], label=disp)\n",
    "    ax.fill_between(dfp[\"Year\"], dfp[\"lo\"], dfp[\"hi\"], alpha=0.20, linewidth=0, color=color_map[disp])\n",
    "    ax.axhline(0, linestyle=\"--\", linewidth=1, color=\"k\")\n",
    "    ax.grid(True, which=\"major\", linestyle=\"--\", linewidth=0.5, alpha=0.4)  # subtle grid\n",
    "    ax.set_title(disp, fontsize=14, fontweight=\"normal\")  # <-- not bold\n",
    "    ax.set_xlabel(\"Year\", fontsize=12)\n",
    "\n",
    "axes[0].set_ylabel(\"Units of CO₂ Eff.\", fontsize=12)\n",
    "axes[2].set_ylabel(\"Units of CO₂ Eff.\", fontsize=12)\n",
    "fig.suptitle(\"Change Relative to Each Type's Own 2018 Baseline\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = os.path.join(fig_dir, \"interaction_main_types_Fig1.svg\")\n",
    "plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")  # ✅ vector + raster mix\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# =========================================================\n",
    "# FIGURE 2: Cross-type gap vs Bulk carrier (same year)\n",
    "# =========================================================\n",
    "\n",
    "# Build Δ_{c,t} = φ_c + ψ_{c,t}\n",
    "rows = []\n",
    "for cat in [\"Oil_tanker\", \"Chemical_tanker\", \"Container_ship\"]:\n",
    "    for y in years:\n",
    "        terms = [cat]  # φ_c\n",
    "        inter = f\"{cat}_x_year_{y}\"\n",
    "        if y != 2018 and inter in params.index:\n",
    "            terms.append(inter)\n",
    "        est, se = lincomb(terms)\n",
    "        rows.append({\n",
    "            \"CategorySan\": cat,\n",
    "            \"CategoryDisp\": sanitized_to_display.get(cat, cat),\n",
    "            \"Year\": y,\n",
    "            \"Estimate\": est,\n",
    "            \"SE\": se,\n",
    "            \"lo\": est - 1.96 * se,\n",
    "            \"hi\": est + 1.96 * se\n",
    "        })\n",
    "\n",
    "df_gap = pd.DataFrame(rows)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "for disp_name in [\"Oil tanker\", \"Chemical tanker\", \"Container ship\"]:\n",
    "    san = display_to_sanitized.get(disp_name, disp_name)\n",
    "    g = df_gap[df_gap[\"CategorySan\"] == san].sort_values(\"Year\")\n",
    "    if g.empty:\n",
    "        continue\n",
    "    ax.plot(g[\"Year\"], g[\"Estimate\"], marker=\"o\", label=disp_name, color=color_map[disp_name])\n",
    "    ax.fill_between(g[\"Year\"], g[\"lo\"], g[\"hi\"], alpha=0.20, linewidth=0, color=color_map[disp_name])\n",
    "\n",
    "# Dotted zero reference line for Bulk carrier (no horizontal dashed line)\n",
    "ax.plot(years, [0]*len(years), linestyle=\":\", linewidth=2, color=color_map[\"Bulk carrier\"], label=\"Bulk carrier\")\n",
    "\n",
    "# Removed ax.axhline(0, ...) line here\n",
    "ax.grid(True, which=\"major\", linestyle=\"--\", linewidth=0.5, alpha=0.4)  # subtle grid\n",
    "ax.set_xlabel(\"Year\", fontsize=12)\n",
    "ax.set_ylabel(\"Units of CO₂ Eff.\", fontsize=12)\n",
    "ax.set_title(\"Gap vs Bulk of Same Year\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Clean legend order\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "lab2hdl = {lab: h for h, lab in zip(handles, labels)}\n",
    "ordered_labels  = [lab for lab in legend_order if lab in lab2hdl]\n",
    "ordered_handles = [lab2hdl[lab] for lab in ordered_labels]\n",
    "ax.legend(ordered_handles, ordered_labels, ncol=2)\n",
    "\n",
    "save_path = os.path.join(fig_dir, \"interaction_main_types_Fig2.svg\")\n",
    "plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")  # ✅ vector + raster mix\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d28529-4161-4f05-b6ed-1587f74528bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#---EXPORT TABLES---#\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Extract coefficients ===\n",
    "params = cre_res.params\n",
    "\n",
    "# Identify year dummies, ship-type dummies, and interactions\n",
    "year_cols = [c for c in params.index if c.startswith(\"year_\")]\n",
    "ship_cols = [c for c in params.index if (c not in year_cols and \"_x_\" not in c \n",
    "             and c not in [\"Intercept\",\"Speed\",\"Age\",\"Speed_mean\",\"Age_mean\",\"TEI\",\"DWT\"])]\n",
    "interaction_cols = [c for c in params.index if \"_x_\" in c]\n",
    "\n",
    "# --- Parse into dicts ---\n",
    "# Year effects (baseline 2018 = 0)\n",
    "year_effects = {2018: 0.0}\n",
    "for c in year_cols:\n",
    "    yr = int(c.split(\"_\")[1])\n",
    "    year_effects[yr] = params[c]\n",
    "\n",
    "# Ship-type dummies\n",
    "ship_dummies = {c: params[c] for c in ship_cols}\n",
    "\n",
    "# Interactions\n",
    "interactions = {}\n",
    "for c in interaction_cols:\n",
    "    ship, yr = c.split(\"_x_\")\n",
    "    yr = int(yr.split(\"_\")[1])\n",
    "    if ship not in interactions:\n",
    "        interactions[ship] = {}\n",
    "    interactions[ship][yr] = params[c]\n",
    "\n",
    "# Ensure order\n",
    "years = sorted(year_effects.keys())\n",
    "ships = [\"Bulk_Carrier\"] + list(ship_dummies.keys())\n",
    "\n",
    "# === Table 1: Evolution vs own 2018 baseline ===\n",
    "data_evolution = {}\n",
    "for ship in ships:\n",
    "    vals = []\n",
    "    for y in years:\n",
    "        if ship == \"Bulk_Carrier\":\n",
    "            val = year_effects[y]   # Bulk Carrier evolution vs 2018\n",
    "        else:\n",
    "            base = year_effects[y]\n",
    "            inter = interactions.get(ship, {}).get(y, 0.0)\n",
    "            val = base + inter      # relative to own 2018\n",
    "        vals.append(round(val, 4))\n",
    "    data_evolution[ship] = vals\n",
    "\n",
    "df_evolution = pd.DataFrame(data_evolution, index=years)\n",
    "\n",
    "# === Table 2: Comparison vs Bulk Carrier 2018 baseline ===\n",
    "# Bulk Carrier 2018 = 0 by construction\n",
    "data_vs_bulk2018 = {}\n",
    "for ship in ships:\n",
    "    vals = []\n",
    "    for y in years:\n",
    "        if ship == \"Bulk_Carrier\":\n",
    "            val = year_effects[y]  # Bulk Carrier vs 2018\n",
    "        else:\n",
    "            ship_val = ship_dummies[ship]\n",
    "            year_val = year_effects[y]\n",
    "            inter_val = interactions.get(ship, {}).get(y, 0.0)\n",
    "            val = ship_val + year_val + inter_val\n",
    "        vals.append(round(val, 4))\n",
    "    data_vs_bulk2018[ship] = vals\n",
    "\n",
    "df_vs_bulk2018 = pd.DataFrame(data_vs_bulk2018, index=years)\n",
    "\n",
    "# === Show results ===\n",
    "print(\"\\n=== Table 1: Evolution vs own 2018 baseline ===\")\n",
    "print(df_evolution)\n",
    "\n",
    "print(\"\\n=== Table 2: Comparison vs Bulk Carrier 2018 baseline ===\")\n",
    "print(df_vs_bulk2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c7506-597a-427e-ab8f-5c75dbfc0138",
   "metadata": {},
   "source": [
    "## 7.3 ---- The Bulk Panel Regression Model -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98007e4-fd02-48ff-a12b-51458245a57e",
   "metadata": {},
   "source": [
    "### 7.3.1 CRE Model with Dummy Years and Types and Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841fa302-e90d-41c9-870a-8feee47fbd00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- bulk model ----- #\n",
    "\n",
    "import pandas as pd\n",
    "from linearmodels.panel import RandomEffects\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "bulk_panel = panel_df[panel_df[\"Ship_type\"] == \"Bulk carrier\"].copy()\n",
    "bulk_panel.columns = (bulk_panel.columns\n",
    "                .str.strip()\n",
    "                .str.replace(\" \", \"_\")\n",
    "                .str.replace(r\"\\.\", \"\", regex=True))\n",
    "# -----------------------------\n",
    "# 1) Work only with Bulk carriers\n",
    "# -----------------------------\n",
    "df_cre = bulk_panel.set_index(['IMO_Number','Reporting_Period']).copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Mundlak means for time-varying vars\n",
    "# -----------------------------\n",
    "time_varying = ['Speed','Age']\n",
    "means = df_cre.groupby(level=0)[time_varying].transform('mean').add_suffix('_mean')\n",
    "df_cre = df_cre.join(means)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Year dummies\n",
    "# -----------------------------\n",
    "years = df_cre.index.get_level_values('Reporting_Period')\n",
    "year_dummies = pd.get_dummies(years, prefix=\"year\", drop_first=True)\n",
    "year_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(year_dummies)\n",
    "year_terms = \" + \".join(year_dummies.columns)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Category dummies (baseline = first category, --> Capesize)\n",
    "# -----------------------------\n",
    "cat_dummies = pd.get_dummies(df_cre['Category'], drop_first=True)\n",
    "\n",
    "# sanitize column names\n",
    "cat_dummies.columns = (cat_dummies.columns\n",
    "                       .str.strip()\n",
    "                       .str.replace(r'\\s+', '_', regex=True)\n",
    "                       .str.replace(r'\\W+', '', regex=True))\n",
    "\n",
    "cat_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(cat_dummies)\n",
    "cat_terms = \" + \".join(cat_dummies.columns)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Interactions: Category × Year\n",
    "# -----------------------------\n",
    "interaction_terms = []\n",
    "for cat in cat_dummies.columns:\n",
    "    for year in year_dummies.columns:\n",
    "        inter_name = f\"{cat}_x_{year}\"\n",
    "        df_cre[inter_name] = df_cre[cat] * df_cre[year]\n",
    "        interaction_terms.append(inter_name)\n",
    "\n",
    "interaction_str = \" + \".join(interaction_terms)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Build formula\n",
    "# -----------------------------\n",
    "formula = (\n",
    "    \"CO2_Eff ~ 1 + \"\n",
    "    \"Speed + Age \"                 # within-vessel effects\n",
    "    \"+ Speed_mean + Age_mean \"     # between-vessel averages (Mundlak)\n",
    "    \"+ TEI + DWT \"                 # time-invariant vessel-level regressors\n",
    "    f\"+ {year_terms} \"             # year dummies\n",
    "    f\"+ {cat_terms} \"              # category dummies\n",
    "    f\"+ {interaction_str}\"         # category × year interactions\n",
    ")\n",
    "\n",
    "print(\"Using formula:\\n\", formula, \"\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Fit CRE model\n",
    "# -----------------------------\n",
    "cre_model = RandomEffects.from_formula(formula, data=df_cre)\n",
    "cre_res = cre_model.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(cre_res.summary)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Mundlak joint test (means)\n",
    "# -----------------------------\n",
    "mean_vars = ['Speed_mean','Age_mean']\n",
    "beta = cre_res.params[mean_vars].values\n",
    "V = cre_res.cov.loc[mean_vars, mean_vars].values\n",
    "wald = float(beta.T @ np.linalg.inv(V) @ beta)\n",
    "pval = chi2.sf(wald, len(mean_vars))\n",
    "print(\"\\nMundlak test χ²:\", wald, \" p-value:\", pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f208b25-48c4-4cc7-af69-f15ceb05a1c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#--- BULK CARRIERS ONLY: SPEED² & PLOT WITH MEAN SHIFT ---#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from linearmodels.panel import RandomEffects\n",
    "from scipy.stats import chi2\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "\n",
    "# === 1. Prepare bulk carrier panel ===\n",
    "bulk_df = panel_df[panel_df[\"Ship type\"] == \"Bulk carrier\"].copy()\n",
    "bulk_df.columns = (\n",
    "    bulk_df.columns\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(r\"\\.\", \"\", regex=True)\n",
    ")\n",
    "df_cre = bulk_df.set_index(['IMO_Number', 'Reporting_Period']).copy()\n",
    "\n",
    "# === 2. Mundlak means for time-varying vars ===\n",
    "time_varying = ['Speed', 'Age']\n",
    "means = df_cre.groupby(level=0)[time_varying].transform('mean').add_suffix('_mean')\n",
    "df_cre = df_cre.join(means)\n",
    "\n",
    "# === 3. Center speed and create squared term ===\n",
    "mean_speed = df_cre['Speed'].mean()\n",
    "df_cre['Speed_c'] = df_cre['Speed'] - mean_speed\n",
    "df_cre['Speed_c_sq'] = df_cre['Speed_c'] ** 2\n",
    "\n",
    "# Add between-vessel averages (Mundlak)\n",
    "df_cre['Speed_c_mean'] = df_cre.groupby(level=0)['Speed_c'].transform('mean')\n",
    "df_cre['Speed_c_sq_mean'] = df_cre.groupby(level=0)['Speed_c_sq'].transform('mean')\n",
    "\n",
    "# === 4. Year dummies ===\n",
    "years = df_cre.index.get_level_values('Reporting_Period')\n",
    "year_dummies = pd.get_dummies(years, prefix=\"year\", drop_first=True)\n",
    "year_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(year_dummies)\n",
    "year_terms = \" + \".join(year_dummies.columns)\n",
    "\n",
    "# === 5. Size category dummies (baseline: Capesize) ===\n",
    "cat_dummies = pd.get_dummies(df_cre['Category'], drop_first=True)\n",
    "cat_dummies.columns = (\n",
    "    cat_dummies.columns\n",
    "    .str.strip()\n",
    "    .str.replace(r'\\s+', '_', regex=True)\n",
    "    .str.replace(r'\\W+', '', regex=True)\n",
    ")\n",
    "cat_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(cat_dummies)\n",
    "cat_terms = \" + \".join(cat_dummies.columns)\n",
    "\n",
    "# === 6. Interactions: Category × Year ===\n",
    "interaction_terms = []\n",
    "for cat in cat_dummies.columns:\n",
    "    for year in year_dummies.columns:\n",
    "        inter_name = f\"{cat}_x_{year}\"\n",
    "        df_cre[inter_name] = df_cre[cat] * df_cre[year]\n",
    "        interaction_terms.append(inter_name)\n",
    "interaction_str = \" + \".join(interaction_terms)\n",
    "\n",
    "# === 7. Build and fit CRE model ===\n",
    "formula = (\n",
    "    \"CO2_Eff ~ 1 + \"\n",
    "    \"Speed_c + Speed_c_sq + Age \"\n",
    "    \"+ Speed_c_mean + Speed_c_sq_mean + Age_mean \"\n",
    "    \"+ TEI + DWT \"\n",
    "    f\"+ {year_terms} + {cat_terms} + {interaction_str}\"\n",
    ")\n",
    "cre_model = RandomEffects.from_formula(formula, data=df_cre)\n",
    "cre_res = cre_model.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(cre_res.summary)\n",
    "\n",
    "# === 8. Compute turning point and its 95% CI ===\n",
    "b1 = cre_res.params['Speed_c']\n",
    "b2 = cre_res.params['Speed_c_sq']\n",
    "cov_b1b2 = cre_res.cov.loc['Speed_c', 'Speed_c_sq']\n",
    "var_b1 = cre_res.cov.loc['Speed_c', 'Speed_c']\n",
    "var_b2 = cre_res.cov.loc['Speed_c_sq', 'Speed_c_sq']\n",
    "\n",
    "speed_star = -b1 / (2 * b2) + mean_speed\n",
    "\n",
    "d_b1 = -1 / (2 * b2)\n",
    "d_b2 = b1 / (2 * (b2 ** 2))\n",
    "var_speed_star = (d_b1 ** 2) * var_b1 + (d_b2 ** 2) * var_b2 + 2 * d_b1 * d_b2 * cov_b1b2\n",
    "se_speed_star = np.sqrt(var_speed_star)\n",
    "\n",
    "ci_lower = float(speed_star - 1.96 * se_speed_star)\n",
    "ci_upper = float(speed_star + 1.96 * se_speed_star)\n",
    "\n",
    "print(f\"Turning point: {speed_star:.2f} kn\")\n",
    "print(f\"95% CI for turning point: [{ci_lower:.2f}, {ci_upper:.2f}] kn\")\n",
    "\n",
    "# === 8.1 Compute mean shift (C) ===\n",
    "\n",
    "# 1) Continuous controls mean contribution\n",
    "controls = ['Age', 'Speed_c_mean', 'Speed_c_sq_mean', 'Age_mean', 'TEI', 'DWT']\n",
    "C_controls = sum(cre_res.params[v] * df_cre[v].mean() for v in controls if v in cre_res.params.index)\n",
    "\n",
    "# 2) Mean of year effects\n",
    "year_coef_names = [c for c in cre_res.params.index if c.startswith('year_')]\n",
    "C_year = float(np.mean(cre_res.params[year_coef_names])) if year_coef_names else 0.0\n",
    "\n",
    "# 3) Mean of size category effects\n",
    "cat_coef_names = [c for c in cat_dummies.columns if c in cre_res.params.index]\n",
    "C_cat = float(np.mean(cre_res.params[cat_coef_names])) if cat_coef_names else 0.0\n",
    "\n",
    "# ✅ Total shift (excluding interactions)\n",
    "C = C_controls + C_year + C_cat\n",
    "\n",
    "# === 9. Build prediction curve and confidence bands ===\n",
    "speeds = np.linspace(8, 17, 300)\n",
    "sc = speeds - mean_speed\n",
    "\n",
    "mu = (cre_res.params['Intercept'] +\n",
    "      cre_res.params['Speed_c'] * sc +\n",
    "      cre_res.params['Speed_c_sq'] * sc**2 + C)\n",
    "\n",
    "cov = cre_res.cov.loc[['Intercept', 'Speed_c', 'Speed_c_sq'],\n",
    "                      ['Intercept', 'Speed_c', 'Speed_c_sq']].values\n",
    "X = np.vstack([np.ones_like(sc), sc, sc**2]).T\n",
    "se = np.sqrt(np.sum(X @ cov * X, axis=1))\n",
    "\n",
    "upper = mu + 1.96 * se\n",
    "lower = mu - 1.96 * se\n",
    "\n",
    "idx_lo = np.argmin(lower)\n",
    "idx_hi = np.argmin(upper)\n",
    "x_lo, x_hi = speeds[idx_lo], speeds[idx_hi]\n",
    "print(f\"Argmin of lower band: {x_lo:.2f} kn\")\n",
    "print(f\"Argmin of upper band: {x_hi:.2f} kn\")\n",
    "\n",
    "# === 10. Plot results ===\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "ax.plot(speeds, mu, color=\"firebrick\", linewidth=2, label=\"Estimated CO₂ Efficiency\")\n",
    "ax.fill_between(speeds, lower, upper, color=\"firebrick\", alpha=0.2, label=\"95% CI of CO₂ Efficiency\")\n",
    "\n",
    "ax.axvline(speed_star, color=\"gray\", linestyle=\"--\", linewidth=1.5, label=f\"Optimal Speed ≈ {speed_star:.2f} kn\")\n",
    "ax.axvline(ci_lower, color=\"gray\", linestyle=\":\", linewidth=1.2, label=f\"Lower CI ≈ {ci_lower:.2f} kn\")\n",
    "ax.axvline(ci_upper, color=\"gray\", linestyle=\":\", linewidth=1.2, label=f\"Upper CI ≈ {ci_upper:.2f} kn\")\n",
    "ax.axvspan(ci_lower, ci_upper, color=\"gray\", alpha=0.15, label=\"95% CI of Optimal Speed\")\n",
    "\n",
    "# Annotate turning point (with C)\n",
    "eff_star = (cre_res.params['Intercept'] +\n",
    "            cre_res.params['Speed_c'] * (speed_star - mean_speed) +\n",
    "            cre_res.params['Speed_c_sq'] * (speed_star - mean_speed)**2 + C)\n",
    "ax.scatter(speed_star, eff_star, color=\"black\", s=70, zorder=5, label=\"Turning Point\")\n",
    "ax.text(speed_star + 0.1, eff_star, f\"{speed_star:.2f} kn\", fontsize=12, va=\"bottom\")\n",
    "\n",
    "# Show minima of upper and lower bands\n",
    "eff_lo = lower[idx_lo]\n",
    "eff_hi = upper[idx_hi]\n",
    "ax.scatter(x_lo, eff_lo, color=\"blue\", s=70, zorder=5, marker='o', label=\"Min Lower Band\")\n",
    "ax.scatter(x_hi, eff_hi, color=\"green\", s=70, zorder=5, marker='o', label=\"Min Upper Band\")\n",
    "ax.text(x_lo + 0.1, eff_lo, f\"{x_lo:.2f} kn\", fontsize=12, color=\"blue\", va=\"bottom\")\n",
    "ax.text(x_hi + 0.1, eff_hi, f\"{x_hi:.2f} kn\", fontsize=12, color=\"green\", va=\"bottom\")\n",
    "\n",
    "# Annotate CI bounds\n",
    "y_min_for_text = ax.get_ylim()[0] - 0.1\n",
    "ax.text(ci_lower, y_min_for_text, f\"{ci_lower:.2f} kn\", fontsize=11, ha=\"center\", va=\"top\", color=\"gray\")\n",
    "ax.text(ci_upper, y_min_for_text, f\"{ci_upper:.2f} kn\", fontsize=11, ha=\"center\", va=\"top\", color=\"gray\")\n",
    "\n",
    "# === ✅ Aesthetics ===\n",
    "ax.set_xticks(np.arange(8, 18, 1))\n",
    "ax.set_xlabel(\"Speed [knots]\", fontsize=14)\n",
    "ax.set_ylabel(\"Estimated CO₂ Efficiency [gCO₂/t·nm]\", fontsize=14)\n",
    "ax.set_title(\"U-Shaped Relationship Between Speed and CO₂ Efficiency\\n(Bulk Carriers Only)\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "# ✅ Set Y-axis to start at 7 and go by 1\n",
    "ax.set_yticks(np.arange(7, np.ceil(np.max(upper)) + 1, 1))\n",
    "ax.set_ylim(7, np.ceil(np.max(upper)) + 0.2)\n",
    "\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "ax.legend(loc='lower right', fontsize=10, frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# === Save figure ===\n",
    "save_path = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\\bulk_speed_curves.svg\"\n",
    "plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Bulk carrier figure saved successfully to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ee875-4ef5-4026-ac65-ca388e0eaa52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export results\n",
    "table = export_cre_results(cre_res, \"Bulk_Model_Speed\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720fab08-a31c-464c-852d-f7b323e1980a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Dual Plot: Elasticity + Natural Scale for TEI (Bulk Carriers Only) --- #\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from linearmodels.panel import RandomEffects\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# === 1. Filter to Bulk Carriers Only ===\n",
    "df = panel_df.copy()\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(r\"\\.\", \"\", regex=True)\n",
    ")\n",
    "df = df[df[\"Ship_type\"] == \"Bulk carrier\"].copy()\n",
    "df_cre = df.set_index(['IMO_Number', 'Reporting_Period']).copy()\n",
    "\n",
    "# === 2. Log-transform variables ===\n",
    "df_cre['log_CO2_Eff'] = np.log(df_cre['CO2_Eff'])\n",
    "df_cre['log_Speed'] = np.log(df_cre['Speed'])\n",
    "df_cre['log_TEI'] = np.log(df_cre['TEI'])\n",
    "df_cre['log_DWT'] = np.log(df_cre['DWT'])\n",
    "\n",
    "# === 3. Mundlak means ===\n",
    "time_varying_log = ['log_Speed', 'Age']\n",
    "means_log = df_cre.groupby(level=0)[time_varying_log].transform('mean').add_suffix('_mean')\n",
    "df_cre = df_cre.join(means_log)\n",
    "\n",
    "# === 4. Quadratic term ===\n",
    "df_cre['log_TEI_sq'] = df_cre['log_TEI'] ** 2\n",
    "\n",
    "# === 5. Year dummies ===\n",
    "years = df_cre.index.get_level_values('Reporting_Period')\n",
    "year_dummies = pd.get_dummies(years, prefix=\"year\", drop_first=True)\n",
    "year_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(year_dummies)\n",
    "year_terms = \" + \".join(year_dummies.columns)\n",
    "\n",
    "# === 6. Category dummies ===\n",
    "cat_dummies = pd.get_dummies(df_cre['Category'], drop_first=True)\n",
    "cat_dummies.columns = (\n",
    "    cat_dummies.columns\n",
    "    .str.strip()\n",
    "    .str.replace(r'\\s+', '_', regex=True)\n",
    "    .str.replace(r'\\W+', '', regex=True)\n",
    ")\n",
    "cat_dummies.index = df_cre.index\n",
    "df_cre = df_cre.join(cat_dummies)\n",
    "cat_terms = \" + \".join(cat_dummies.columns)\n",
    "\n",
    "# === 7. Interaction terms: Category × Year ===\n",
    "interaction_terms = []\n",
    "for cat in cat_dummies.columns:\n",
    "    for year in year_dummies.columns:\n",
    "        inter_name = f\"{cat}_x_{year}\"\n",
    "        df_cre[inter_name] = df_cre[cat] * df_cre[year]\n",
    "        interaction_terms.append(inter_name)\n",
    "interaction_str = \" + \".join(interaction_terms)\n",
    "\n",
    "# === 8. Fit CRE model with interactions ===\n",
    "formula_nl = (\n",
    "    \"log_CO2_Eff ~ 1 + \"\n",
    "    \"log_Speed + Age + log_TEI + log_TEI_sq + log_DWT \"\n",
    "    \"+ log_Speed_mean + Age_mean \"\n",
    "    f\"+ {year_terms} + {cat_terms} + {interaction_str}\"\n",
    ")\n",
    "cre_model_nl = RandomEffects.from_formula(formula_nl, data=df_cre)\n",
    "cre_res_nl = cre_model_nl.fit(cov_type=\"clustered\", cluster_entity=True)\n",
    "print(cre_res_nl.summary)\n",
    "\n",
    "# === 9. Extract coefficients ===\n",
    "b0 = cre_res_nl.params['Intercept']\n",
    "b1 = cre_res_nl.params['log_TEI']\n",
    "b2 = cre_res_nl.params['log_TEI_sq']\n",
    "\n",
    "# === 10. TEI Range ===\n",
    "log_tei_range = np.linspace(df_cre['log_TEI'].quantile(0.05), df_cre['log_TEI'].quantile(0.95), 200)\n",
    "tei_range = np.exp(log_tei_range)\n",
    "\n",
    "# === 11. Elasticity ===\n",
    "elasticity = b1 + 2 * b2 * log_tei_range\n",
    "\n",
    "var_b1 = cre_res_nl.cov.loc['log_TEI', 'log_TEI']\n",
    "var_b2 = cre_res_nl.cov.loc['log_TEI_sq', 'log_TEI_sq']\n",
    "cov_b1b2 = cre_res_nl.cov.loc['log_TEI', 'log_TEI_sq']\n",
    "\n",
    "se_elasticity = np.sqrt(\n",
    "    var_b1 + (2 * log_tei_range) ** 2 * var_b2 + 2 * (2 * log_tei_range) * cov_b1b2\n",
    ")\n",
    "upper_el = elasticity + 1.96 * se_elasticity\n",
    "lower_el = elasticity - 1.96 * se_elasticity\n",
    "\n",
    "# === 12. Predicted CO₂ Efficiency (controlling for other vars) ===\n",
    "X_means = {\n",
    "    'log_Speed': df_cre['log_Speed'].mean(),\n",
    "    'Age': df_cre['Age'].mean(),\n",
    "    'log_DWT': df_cre['log_DWT'].mean(),\n",
    "    'log_Speed_mean': df_cre['log_Speed_mean'].mean(),\n",
    "    'Age_mean': df_cre['Age_mean'].mean()\n",
    "}\n",
    "\n",
    "log_pred = (\n",
    "    b0\n",
    "    + b1 * log_tei_range\n",
    "    + b2 * log_tei_range**2\n",
    "    + cre_res_nl.params['log_Speed'] * X_means['log_Speed']\n",
    "    + cre_res_nl.params['Age'] * X_means['Age']\n",
    "    + cre_res_nl.params['log_DWT'] * X_means['log_DWT']\n",
    "    + cre_res_nl.params['log_Speed_mean'] * X_means['log_Speed_mean']\n",
    "    + cre_res_nl.params['Age_mean'] * X_means['Age_mean']\n",
    ")\n",
    "\n",
    "# === Add mean year, category, and interaction effects ===\n",
    "for col in year_dummies.columns:\n",
    "    if col in cre_res_nl.params.index:\n",
    "        log_pred += cre_res_nl.params[col] * df_cre[col].mean()\n",
    "\n",
    "for col in cat_dummies.columns:\n",
    "    if col in cre_res_nl.params.index:\n",
    "        log_pred += cre_res_nl.params[col] * df_cre[col].mean()\n",
    "\n",
    "for col in interaction_terms:\n",
    "    if col in cre_res_nl.params.index:\n",
    "        log_pred += cre_res_nl.params[col] * df_cre[col].mean()\n",
    "\n",
    "predicted_eff = np.exp(log_pred)\n",
    "\n",
    "# === 13. Plot both ===\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# --- (A) Elasticity Plot ---\n",
    "axes[0].plot(log_tei_range, elasticity, color=\"firebrick\", linewidth=2, label=\"Elasticity\")\n",
    "axes[0].fill_between(log_tei_range, lower_el, upper_el, color=\"firebrick\", alpha=0.2, label=\"95% CI\")\n",
    "axes[0].axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "axes[0].set_xlabel(\"log(TEI)\", fontsize=14)\n",
    "axes[0].set_ylabel(\"Marginal Elasticity of CO₂ Efficiency\", fontsize=14)\n",
    "axes[0].set_title(\"(A) Elasticity Curve (log–log model)\", fontsize=15, fontweight=\"bold\")\n",
    "axes[0].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "axes[0].legend(fontsize=11, loc='best')\n",
    "\n",
    "# --- (B) Natural Scale Plot ---\n",
    "axes[1].plot(tei_range, predicted_eff, color=\"navy\", linewidth=2, label=\"Predicted CO₂ Efficiency\")\n",
    "axes[1].set_xlabel(\"TEI\", fontsize=14)\n",
    "axes[1].set_ylabel(\"Predicted CO₂ Efficiency [gCO₂/t·nm]\", fontsize=14)\n",
    "axes[1].set_title(\"(B) Predicted CO₂ Efficiency vs. TEI (Natural Scale)\", fontsize=15, fontweight=\"bold\")\n",
    "axes[1].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "axes[1].legend(fontsize=11, loc='best')\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Elasticity vs. Natural Relationship of TEI and CO₂ Efficiency (Bulk Carriers)\",\n",
    "    fontsize=19,\n",
    "    fontweight=\"bold\",\n",
    "    y=0.95  # ↓ Moves the title closer to the subplots (default is ≈ 0.98–0.99)\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 0.94, 0.96])\n",
    "\n",
    "# === Save ===\n",
    "save_path = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\\tei_elasticity_vs_levels_bulk.svg\"\n",
    "plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Figure saved successfully to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e8faf-45ce-42e8-8cf9-898ccb36487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results\n",
    "table = export_cre_results(cre_res_nl, \"Bulk_Model_Log\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4ca45-b51c-4b78-aade-3f5459113ce6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- VIF Diagnostics for Panel Model --- #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# 1️⃣ Build the design matrix (X) from the same df_cre used in your regression\n",
    "X = df_cre.copy().drop(columns=[\"CO2_Eff\"], errors=\"ignore\")\n",
    "\n",
    "# Only keep numeric variables\n",
    "X = X.select_dtypes(include=[np.number]).fillna(0)\n",
    "\n",
    "# Add constant (intercept) for VIF calculation\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# 2️⃣ Compute VIF for all variables\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# 3️⃣ Identify continuous vs. dummy variables\n",
    "continuous_vars = [\"Speed\", \"Age\", \"Speed_mean\", \"Age_mean\", \"TEI\", \"DWT\"]  # edit if needed\n",
    "\n",
    "def classify_var(name):\n",
    "    if name in continuous_vars:\n",
    "        return \"Continuous\"\n",
    "    elif name == \"const\":\n",
    "        return \"Constant\"\n",
    "    else:\n",
    "        return \"Dummy/Interaction\"\n",
    "\n",
    "vif_data[\"Type\"] = vif_data[\"feature\"].apply(classify_var)\n",
    "\n",
    "# 4️⃣ Sort by VIF and show top 10\n",
    "vif_top10 = vif_data.sort_values(\"VIF\", ascending=False).head(10)\n",
    "\n",
    "print(\"\\n📊 Top 10 Variables by VIF:\\n\")\n",
    "print(vif_top10.to_string(index=False))\n",
    "\n",
    "# Optional: export full VIF table\n",
    "vif_data_sorted = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "vif_data_sorted.to_csv(\"vif_results.csv\", index=False)\n",
    "print(\"\\n✅ Full VIF table saved as 'vif_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66fbe5-759d-4988-bc78-53936aae2290",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Plotting Interactions for Bulk Carrier Size Categories (Mini Bulk Excluded) ---#\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Folder to save ===\n",
    "fig_dir = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\"\n",
    "\n",
    "# ----- Inputs from your fitted model -----\n",
    "params = cre_res.params\n",
    "cov    = cre_res.cov\n",
    "\n",
    "# ===== COMMON SETUP =====\n",
    "year_cols = [c for c in params.index if c.startswith(\"year_\")]\n",
    "years = [2018] + sorted(int(c.split(\"_\")[1]) for c in year_cols)\n",
    "\n",
    "# ✅ Colormap (from your legend, Mini Bulk excluded)\n",
    "color_map = {\n",
    "    \"Handysize\": \"#ff7f0e\",          # orange\n",
    "    \"Handymax\": \"#2ca02c\",           # green\n",
    "    \"Supramax\": \"#d62728\",           # red\n",
    "    \"Panamax\": \"#9467bd\",            # purple\n",
    "    \"Capesize\": \"#8c564b\"            # brown (baseline)\n",
    "}\n",
    "\n",
    "# Mapping for display names\n",
    "sanitized_to_display = {\n",
    "    \"Handysize\": \"Handysize\",\n",
    "    \"Handymax\": \"Handymax\",\n",
    "    \"Supramax\": \"Supramax\",\n",
    "    \"Panamax\": \"Panamax\",\n",
    "    \"Capesize\": \"Capesize\"\n",
    "}\n",
    "\n",
    "# ✅ Order categories (Mini Bulk removed)\n",
    "panel_order = [\"Capesize\", \"Handysize\", \"Handymax\", \"Supramax\", \"Panamax\"]\n",
    "\n",
    "# ----- Helper: linear combination -----\n",
    "def lincomb(varnames):\n",
    "    a = np.zeros(len(params))\n",
    "    any_hit = False\n",
    "    for v in varnames:\n",
    "        if v in params.index:\n",
    "            a[params.index.get_loc(v)] += 1.0\n",
    "            any_hit = True\n",
    "    est = float(a @ params.values) if any_hit else 0.0\n",
    "    se  = float(np.sqrt(a @ cov.values @ a)) if any_hit else 0.0\n",
    "    return est, se\n",
    "\n",
    "# =========================================================\n",
    "# FIGURE 1: Within-category change relative to own 2018 baseline\n",
    "# =========================================================\n",
    "def build_series_for_category(cat):\n",
    "    rows = []\n",
    "    for y in years:\n",
    "        if cat == \"Capesize\":\n",
    "            est, se = (0.0, 0.0) if y == 2018 else lincomb([f\"year_{y}\"])\n",
    "        else:\n",
    "            if y == 2018:\n",
    "                est, se = 0.0, 0.0\n",
    "            else:\n",
    "                terms = [f\"year_{y}\"]\n",
    "                inter = f\"{cat}_x_year_{y}\"\n",
    "                if inter in params.index:\n",
    "                    terms.append(inter)\n",
    "                est, se = lincomb(terms)\n",
    "        rows.append({\"Year\": y, \"Estimate\": est, \"SE\": se})\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"lo\"] = df[\"Estimate\"] - 1.96 * df[\"SE\"]\n",
    "    df[\"hi\"] = df[\"Estimate\"] + 1.96 * df[\"SE\"]\n",
    "    return df\n",
    "\n",
    "# Create 3×2 or 3×1 grid (we have 5 categories)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 10), sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, cat in zip(axes, panel_order):\n",
    "    dfp = build_series_for_category(cat)\n",
    "    display_name = sanitized_to_display.get(cat, cat)\n",
    "    ax.plot(dfp[\"Year\"], dfp[\"Estimate\"], marker=\"o\", color=color_map[cat], label=display_name)\n",
    "    ax.fill_between(dfp[\"Year\"], dfp[\"lo\"], dfp[\"hi\"], alpha=0.20, linewidth=0, color=color_map[cat])\n",
    "    ax.axhline(0, linestyle=\"--\", linewidth=1, color=\"k\")\n",
    "    ax.grid(True, which=\"major\", linestyle=\"--\", linewidth=0.5, alpha=0.4)\n",
    "    ax.set_title(display_name, fontsize=13, fontweight=\"normal\")\n",
    "    ax.set_xlabel(\"Year\", fontsize=11)\n",
    "\n",
    "# Remove any unused subplot if fewer than 6\n",
    "for ax in axes[len(panel_order):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "axes[0].set_ylabel(\"Units of CO₂ Eff.\", fontsize=11)\n",
    "axes[2].set_ylabel(\"Units of CO₂ Eff.\", fontsize=11)\n",
    "axes[4].set_ylabel(\"Units of CO₂ Eff.\", fontsize=11)\n",
    "fig.suptitle(\"Change Relative to Each Size Category's Own 2018 Baseline\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = os.path.join(fig_dir, \"bulk_size_interactions_Fig1.svg\")\n",
    "plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# =========================================================\n",
    "# FIGURE 2: Cross-category gap vs Capesize (same year)\n",
    "# =========================================================\n",
    "\n",
    "# Build Δ_{c,t} = φ_c + ψ_{c,t}\n",
    "rows = []\n",
    "for cat in [c for c in panel_order if c != \"Capesize\"]:\n",
    "    for y in years:\n",
    "        terms = [cat]  # φ_c\n",
    "        inter = f\"{cat}_x_year_{y}\"\n",
    "        if y != 2018 and inter in params.index:\n",
    "            terms.append(inter)\n",
    "        est, se = lincomb(terms)\n",
    "        rows.append({\n",
    "            \"CategorySan\": cat,\n",
    "            \"CategoryDisp\": sanitized_to_display.get(cat, cat),\n",
    "            \"Year\": y,\n",
    "            \"Estimate\": est,\n",
    "            \"SE\": se,\n",
    "            \"lo\": est - 1.96 * se,\n",
    "            \"hi\": est + 1.96 * se\n",
    "        })\n",
    "\n",
    "df_gap = pd.DataFrame(rows)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "for cat in [c for c in panel_order if c != \"Capesize\"]:\n",
    "    display_name = sanitized_to_display[cat]\n",
    "    g = df_gap[df_gap[\"CategorySan\"] == cat].sort_values(\"Year\")\n",
    "    ax.plot(g[\"Year\"], g[\"Estimate\"], marker=\"o\", label=display_name, color=color_map[cat])\n",
    "    ax.fill_between(g[\"Year\"], g[\"lo\"], g[\"hi\"], alpha=0.20, linewidth=0, color=color_map[cat])\n",
    "\n",
    "# Add zero reference (Capesize)\n",
    "ax.plot(years, [0]*len(years), linestyle=\":\", linewidth=2, color=color_map[\"Capesize\"], label=\"Capesize\")\n",
    "\n",
    "ax.grid(True, which=\"major\", linestyle=\"--\", linewidth=0.5, alpha=0.4)\n",
    "ax.set_xlabel(\"Year\", fontsize=12)\n",
    "ax.set_ylabel(\"Units of CO₂ Eff.\", fontsize=12)\n",
    "ax.set_title(\"Gap vs Capesize of Same Year\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "# Legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, ncol=2, fontsize=11)\n",
    "\n",
    "save_path = os.path.join(fig_dir, \"bulk_size_interactions_Fig2.svg\")\n",
    "plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4852711c-8842-44fb-9e5f-b484846c5252",
   "metadata": {},
   "source": [
    "# Plotings for Panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cacfb2-a43f-471f-a0a2-fe07827660c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Time Trends (all types) + Vessel Counts\n",
    "#  - consistent palette\n",
    "#  - legend title fully inside exported SVG\n",
    "# ============================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Global font setup\n",
    "# -----------------------------\n",
    "mpl.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# -----------------------------\n",
    "# Clean column names once\n",
    "# -----------------------------\n",
    "panel_df.columns = (\n",
    "    panel_df.columns\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(r\"\\.\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "# Ensure Reporting_Period is numeric (int)\n",
    "panel_df[\"Reporting_Period\"] = panel_df[\"Reporting_Period\"].astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Compute mean and std per year × ship type\n",
    "# -----------------------------\n",
    "agg_vars = [\"CO2_Eff\", \"TEI\", \"Speed\", \"DWT\", \"Age\"]\n",
    "\n",
    "summary = (\n",
    "    panel_df\n",
    "    .groupby([\"Reporting_Period\", \"Ship_type\"])[agg_vars]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "summary.columns = [f\"{var}_{stat}\" if stat else var\n",
    "                   for var, stat in summary.columns.to_flat_index()]\n",
    "\n",
    "# -----------------------------\n",
    "# Fixed colors for ship types (your palette)\n",
    "# -----------------------------\n",
    "color_map = {\n",
    "    \"Bulk carrier\": \"steelblue\",\n",
    "    \"Oil tanker\": \"firebrick\",\n",
    "    \"Chemical tanker\": \"seagreen\",\n",
    "    \"Container ship\": \"darkorange\"\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Helper: plot mean ± std\n",
    "# -----------------------------\n",
    "def plot_with_cv_errorbars(ax, data, variable, ylabel, title, show_xlabel=False):\n",
    "    handles, labels = [], []\n",
    "    for ship in data[\"Ship_type\"].unique():\n",
    "        subset = data[data[\"Ship_type\"] == ship].sort_values(\"Reporting_Period\")\n",
    "        mean = subset[f\"{variable}_mean\"]\n",
    "        std  = subset[f\"{variable}_std\"]\n",
    "        color = color_map.get(ship, None)\n",
    "\n",
    "        eb = ax.errorbar(\n",
    "            subset[\"Reporting_Period\"], mean,\n",
    "            yerr=std,\n",
    "            fmt=\"o-\", markersize=5, capsize=2,\n",
    "            elinewidth=0.8, alpha=0.85, label=ship,\n",
    "            color=color\n",
    "        )\n",
    "        # Legend handle with consistent style\n",
    "        handles.append(mlines.Line2D([], [], color=eb[0].get_color(),\n",
    "                                     marker='o', linestyle='-'))\n",
    "        labels.append(ship)\n",
    "\n",
    "    ax.set_title(title, fontweight=\"bold\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(sorted(data[\"Reporting_Period\"].unique()))\n",
    "    if show_xlabel:\n",
    "        ax.set_xlabel(\"Reporting Period\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    return handles, labels\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Build subplot grid (3×2)\n",
    "# -----------------------------\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 12), sharex=True)\n",
    "\n",
    "all_handles, all_labels = [], []\n",
    "\n",
    "# Row 1\n",
    "h, l = plot_with_cv_errorbars(\n",
    "    axes[0, 0], summary, \"CO2_Eff\",\n",
    "    \"CO₂ Eff (mean ± sd)\", \"Average CO₂ Efficiency per Year by Ship Type\"\n",
    ")\n",
    "all_handles, all_labels = h, l\n",
    "\n",
    "plot_with_cv_errorbars(\n",
    "    axes[0, 1], summary, \"TEI\",\n",
    "    \"TEI (mean ± sd)\", \"Average TEI per Year by Ship Type\"\n",
    ")\n",
    "\n",
    "# Row 2\n",
    "plot_with_cv_errorbars(\n",
    "    axes[1, 0], summary, \"Speed\",\n",
    "    \"Speed (mean ± sd)\", \"Average Speed per Year by Ship Type\"\n",
    ")\n",
    "\n",
    "plot_with_cv_errorbars(\n",
    "    axes[1, 1], summary, \"DWT\",\n",
    "    \"DWT (mean ± sd)\", \"Average DWT per Year by Ship Type\"\n",
    ")\n",
    "\n",
    "# Row 3\n",
    "plot_with_cv_errorbars(\n",
    "    axes[2, 0], summary, \"Age\",\n",
    "    \"Age (mean ± sd)\", \"Average Age per Year by Ship Type\",\n",
    "    show_xlabel=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Vessel counts per year per ship type (bottom-right panel)\n",
    "# -----------------------------\n",
    "vessel_counts_trend = (\n",
    "    panel_df.groupby([\"Reporting_Period\", \"Ship_type\"])[\"IMO_Number\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"Vessel_Count\")\n",
    ")\n",
    "\n",
    "for ship in vessel_counts_trend[\"Ship_type\"].unique():\n",
    "    subset = vessel_counts_trend[vessel_counts_trend[\"Ship_type\"] == ship] \\\n",
    "             .sort_values(\"Reporting_Period\")\n",
    "    axes[2, 1].plot(\n",
    "        subset[\"Reporting_Period\"], subset[\"Vessel_Count\"],\n",
    "        marker=\"o\", label=ship, color=color_map.get(ship, None)\n",
    "    )\n",
    "\n",
    "axes[2, 1].set_title(\"Number of Vessels per Year by Ship Type\", fontweight=\"bold\")\n",
    "axes[2, 1].set_ylabel(\"Vessels\")\n",
    "axes[2, 1].set_xlabel(\"Reporting Period\")\n",
    "axes[2, 1].set_xticks(sorted(vessel_counts_trend[\"Reporting_Period\"].unique()))\n",
    "axes[2, 1].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Figure-level legend (kept INSIDE the canvas)\n",
    "# -----------------------------\n",
    "fig.legend(\n",
    "    all_handles, all_labels,\n",
    "    title=\"Ship Type\", title_fontsize=15, fontsize=13,\n",
    "    loc=\"upper center\", ncol=4, frameon=True,\n",
    "    bbox_to_anchor=(0.5, 0.98),   # inside the figure\n",
    "    borderaxespad=0.2\n",
    ")\n",
    "plt.setp(fig.legends[0].get_title(), fontweight=\"bold\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final adjustments + SAVE\n",
    "# -----------------------------\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93])  # leave space at top for legend\n",
    "plt.savefig(\n",
    "    r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\\CO2_and_TEI_All_Types.svg\",\n",
    "    format=\"svg\", dpi=300\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# =========================================================\n",
    "# SEPARATE FIGURE: Vessel counts (standalone)\n",
    "# =========================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "for ship in vessel_counts_trend[\"Ship_type\"].unique():\n",
    "    subset = vessel_counts_trend[vessel_counts_trend[\"Ship_type\"] == ship] \\\n",
    "             .sort_values(\"Reporting_Period\")\n",
    "    ax.plot(\n",
    "        subset[\"Reporting_Period\"],\n",
    "        subset[\"Vessel_Count\"],\n",
    "        marker=\"o\", label=ship,\n",
    "        color=color_map.get(ship, None)\n",
    "    )\n",
    "\n",
    "ax.set_title(\"Number of Vessels per Year by Ship Type\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Reporting Period\")\n",
    "ax.set_ylabel(\"Number of Vessels\")\n",
    "ax.set_xticks(sorted(vessel_counts_trend[\"Reporting_Period\"].unique()))\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Legend INSIDE; export covers it fully\n",
    "leg = ax.legend(title=\"Ship Type\", title_fontsize=11, fontsize=9, frameon=True, loc=\"upper left\")\n",
    "plt.setp(leg.get_title(), fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\\Vessel_Counts_All_Types.svg\",\n",
    "    format=\"svg\", dpi=300\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e558022-d716-4216-b84d-3827c4da7460",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- Wald test for statistical significance of interaction terms ---#\n",
    "\n",
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "\n",
    "# 1) collect all interaction parameters\n",
    "inter_vars = [p for p in cre_res.params.index if \"_x_year_\" in p]\n",
    "if not inter_vars:\n",
    "    print(\"No interaction terms found in the model.\")\n",
    "else:\n",
    "    # 2) pull betas and (cluster-robust) covariance, aligned\n",
    "    beta = cre_res.params.reindex(inter_vars).values\n",
    "    V = cre_res.cov.reindex(index=inter_vars, columns=inter_vars).values\n",
    "\n",
    "    # 3) Wald statistic (use pinv for numerical stability)\n",
    "    wald = float(beta.T @ np.linalg.pinv(V) @ beta)\n",
    "    df = len(inter_vars)\n",
    "    pval = chi2.sf(wald, df)\n",
    "\n",
    "    print(f\"Interaction block Wald χ² = {wald:.3f} (df={df}), p = {pval:.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba732635-4d5b-44eb-9732-37b00f59a7c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ----- Trend with Median All types--------#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "# -----------------------------\n",
    "# Global font setup\n",
    "# -----------------------------\n",
    "mpl.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Compute mean, std, median\n",
    "# -----------------------------\n",
    "stats_data = (\n",
    "    df.groupby([\"Reporting_Period\", \"Ship_type\"])\n",
    "      [[\"CO2_Eff\", \"TEI\", \"Speed\", \"DWT\", \"Age\"]]\n",
    "      .agg(['mean','std','median'])\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten column names\n",
    "stats_data.columns = ['Reporting_Period','Ship_type'] + [\n",
    "    f\"{col}_{stat}\" for col, stat in stats_data.columns[2:]\n",
    "]\n",
    "\n",
    "# Ensure Reporting_Period is numeric\n",
    "stats_data[\"Reporting_Period\"] = stats_data[\"Reporting_Period\"].astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Helper: plot mean ± std + median\n",
    "# -----------------------------\n",
    "def plot_with_mean_std_median(ax, data, variable, ylabel, title, show_xlabel=False):\n",
    "    handles, labels = [], []\n",
    "    for ship in data[\"Ship_type\"].unique():\n",
    "        subset = data[data[\"Ship_type\"] == ship]\n",
    "        mean = subset[f\"{variable}_mean\"]\n",
    "        std = subset[f\"{variable}_std\"]\n",
    "        median = subset[f\"{variable}_median\"]\n",
    "\n",
    "        # Mean ± std with error bars\n",
    "        eb = ax.errorbar(\n",
    "            subset[\"Reporting_Period\"], mean,\n",
    "            yerr=std,\n",
    "            fmt=\"o-\", markersize=5, capsize=2,\n",
    "            elinewidth=0.8, alpha=0.7, label=f\"{ship} (mean)\"\n",
    "        )\n",
    "\n",
    "        # Median line\n",
    "        ax.plot(subset[\"Reporting_Period\"], median,\n",
    "                linestyle=\"--\", marker=\"+\", alpha=0.8,\n",
    "                color=eb[0].get_color(), label=f\"{ship} (median)\")\n",
    "\n",
    "        # Legend handles\n",
    "        handles.extend([\n",
    "            mlines.Line2D([], [], color=eb[0].get_color(), marker='o',\n",
    "                          linestyle='-', label=f\"{ship} (mean)\"),\n",
    "            mlines.Line2D([], [], color=eb[0].get_color(), marker='+',\n",
    "                          linestyle='--', label=f\"{ship} (median)\")\n",
    "        ])\n",
    "        labels.extend([f\"{ship} (mean)\", f\"{ship} (median)\"])\n",
    "\n",
    "    ax.set_title(title, fontweight=\"bold\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(sorted(data[\"Reporting_Period\"].unique()))\n",
    "    if show_xlabel:\n",
    "        ax.set_xlabel(\"Year\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    return handles, labels\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Build subplot grid\n",
    "# -----------------------------\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14,12), sharex=True)\n",
    "\n",
    "all_handles, all_labels = [], []\n",
    "\n",
    "h, l = plot_with_mean_std_median(\n",
    "    axes[0,0], stats_data, \"CO2_Eff\",\n",
    "    \"CO₂ Eff (± STD + Median)\", \"Average CO₂ Efficiency per Year by Ship Type\"\n",
    ")\n",
    "all_handles, all_labels = h, l\n",
    "\n",
    "plot_with_mean_std_median(\n",
    "    axes[0,1], stats_data, \"TEI\",\n",
    "    \"TEI (± STD + Median)\", \"Average TEI per Year by Ship Type\"\n",
    ")\n",
    "\n",
    "plot_with_mean_std_median(\n",
    "    axes[1,0], stats_data, \"Speed\",\n",
    "    \"Speed (± STD + Median)\", \"Average Speed per Year by Ship Type\"\n",
    ")\n",
    "\n",
    "plot_with_mean_std_median(\n",
    "    axes[1,1], stats_data, \"DWT\",\n",
    "    \"DWT (± STD + Median)\", \"Average DWT per Year by Ship Type\"\n",
    ")\n",
    "\n",
    "plot_with_mean_std_median(\n",
    "    axes[2,0], stats_data, \"Age\",\n",
    "    \"Age (± STD + Median)\", \"Average Age per Year by Ship Type\",\n",
    "    show_xlabel=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Vessel counts per year per ship type\n",
    "# -----------------------------\n",
    "vessel_counts_trend = (\n",
    "    df.groupby([\"Reporting_Period\",\"Ship_type\"])[\"IMO_Number\"]\n",
    "      .nunique()\n",
    "      .reset_index(name=\"Vessel_Count\")\n",
    ")\n",
    "\n",
    "for ship in vessel_counts_trend[\"Ship_type\"].unique():\n",
    "    subset = vessel_counts_trend[vessel_counts_trend[\"Ship_type\"] == ship]\n",
    "    axes[2,1].plot(subset[\"Reporting_Period\"], subset[\"Vessel_Count\"],\n",
    "                   marker=\"o\", label=ship)\n",
    "\n",
    "axes[2,1].set_title(\"Number of Vessels per Year by Ship Type\", fontweight=\"bold\")\n",
    "axes[2,1].set_ylabel(\"Count\")\n",
    "axes[2,1].set_xlabel(\"Year\")\n",
    "axes[2,1].set_xticks(sorted(vessel_counts_trend[\"Reporting_Period\"].unique()))\n",
    "axes[2,1].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Legend with both mean + median\n",
    "# -----------------------------\n",
    "fig.legend(all_handles, all_labels,\n",
    "           title=\"Ship Type\", title_fontsize=12, fontsize=9,\n",
    "           loc=\"upper center\", ncol=4, frameon=True, bbox_to_anchor=(0.5, 1.02))\n",
    "\n",
    "plt.setp(fig.legends[0].get_title(), fontweight=\"bold\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Save + show\n",
    "# -----------------------------\n",
    "plt.tight_layout(rect=[0,0,1,0.97])  # leave space for legend\n",
    "plt.savefig(r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\\CO2_and_TEI_All_Types_and_Median.svg\",\n",
    "            format=\"svg\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa060f3e-1c2d-4970-95c1-2125d0b8e559",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----- DISTRIBUTIONS -----#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# === Style setup ===\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"axes.titlesize\"] = 15\n",
    "plt.rcParams[\"axes.labelsize\"] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 10\n",
    "plt.rcParams[\"ytick.labelsize\"] = 10\n",
    "\n",
    "# === Colors per ship type ===\n",
    "color_map = {\n",
    "    \"Bulk carrier\": \"steelblue\",\n",
    "    \"Oil tanker\": \"firebrick\",\n",
    "    \"Chemical tanker\": \"seagreen\",\n",
    "    \"Container ship\": \"darkorange\"\n",
    "}\n",
    "\n",
    "ship_order = [\"Bulk carrier\", \"Oil tanker\", \"Chemical tanker\", \"Container ship\"]\n",
    "\n",
    "# === Folder to save ===\n",
    "fig_dir = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\"\n",
    "\n",
    "# ==========================================================\n",
    "# === 1️⃣ INDEPENDENT VARIABLES (2×2): TEI, Speed, Age, DWT ===\n",
    "# ==========================================================\n",
    "plot_vars = [\n",
    "    (\"TEI\", \"TEI [gCO₂ / t·nm]\", \"Technical Efficiency Index\"),\n",
    "    (\"Speed\", \"Speed [knots]\", \"Speed\"),\n",
    "    (\"Age\", \"Age [years]\", \"Age\"),\n",
    "    (\"DWT\", \"DWT [t]\", \"Carrying Capacity\")\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(13, 9))\n",
    "# 🔹 Bring suptitle closer using the y argument\n",
    "fig.suptitle(\"Distributions of Independent Variables\", fontsize=18, fontweight=\"bold\", y=0.93)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (var, xlabel, title) in zip(axes, plot_vars):\n",
    "    for ship in ship_order:\n",
    "        if ship not in panel_df[\"Ship_type\"].unique():\n",
    "            continue\n",
    "        subset = panel_df[panel_df[\"Ship_type\"] == ship]\n",
    "        sns.kdeplot(\n",
    "            subset[var],\n",
    "            fill=True, alpha=0.25, linewidth=1.3,\n",
    "            color=color_map.get(ship, \"gray\"),\n",
    "            ax=ax, label=ship\n",
    "        )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel, labelpad=3)   # bring x-label closer\n",
    "    ax.set_ylabel(\"Density\", labelpad=3)  # bring y-label closer\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    # === Bold legend title ===\n",
    "    leg = ax.legend(title=\"Ship Type\", title_fontsize=10, fontsize=9, frameon=True)\n",
    "    plt.setp(leg.get_title(), fontweight=\"bold\")\n",
    "\n",
    "# Adjust spacing for a cleaner layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93], h_pad=2, w_pad=2)\n",
    "indep_path = os.path.join(fig_dir, \"Distributions_Independent_Variables.svg\")\n",
    "plt.savefig(indep_path, format=\"svg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# === 2️⃣ DEPENDENT VARIABLE: CO₂ Efficiency (KDE curves only) ===\n",
    "# ==========================================================\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# 🔹 Bring suptitle closer here too\n",
    "fig.suptitle(\"Distributions of Dependent Variable\", fontsize=16, fontweight=\"bold\", y=0.92)\n",
    "\n",
    "for ship in ship_order:\n",
    "    if ship not in panel_df[\"Ship_type\"].unique():\n",
    "        continue\n",
    "    subset = panel_df[panel_df[\"Ship_type\"] == ship]\n",
    "    sns.kdeplot(\n",
    "        subset[\"CO2_Eff\"],\n",
    "        fill=True, alpha=0.25, linewidth=1.3,\n",
    "        color=color_map.get(ship, \"gray\"),\n",
    "        ax=ax, label=ship\n",
    "    )\n",
    "\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "ax.set_xlabel(\"CO₂ Efficiency [gCO₂ / t·nm]\", labelpad=3)\n",
    "ax.set_ylabel(\"Density\", labelpad=3)\n",
    "\n",
    "leg = ax.legend(title=\"Ship Type\", title_fontsize=10, fontsize=9, frameon=True)\n",
    "plt.setp(leg.get_title(), fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "dep_path = os.path.join(fig_dir, \"Distributions_CO2_Efficiency.svg\")\n",
    "plt.savefig(dep_path, format=\"svg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130defa-cd4b-4afc-9932-ccbfc811b417",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ----- CO₂ vs Independent Variables (optimized 2×2 subplot) ----- #\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# === Style setup ===\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"axes.titlesize\"] = 15\n",
    "plt.rcParams[\"axes.labelsize\"] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 10\n",
    "plt.rcParams[\"ytick.labelsize\"] = 10\n",
    "\n",
    "# === Colors per ship type ===\n",
    "color_map = {\n",
    "    \"Bulk carrier\": \"steelblue\",\n",
    "    \"Oil tanker\": \"firebrick\",\n",
    "    \"Chemical tanker\": \"seagreen\",\n",
    "    \"Container ship\": \"darkorange\"\n",
    "}\n",
    "\n",
    "ship_order = [\"Bulk carrier\", \"Oil tanker\", \"Chemical tanker\", \"Container ship\"]\n",
    "\n",
    "# === Display names for legend ===\n",
    "legend_labels = {\n",
    "    \"Bulk carrier\": \"Bulk C.\",\n",
    "    \"Oil tanker\": \"Oil T.\",\n",
    "    \"Chemical tanker\": \"Chemical T.\",\n",
    "    \"Container ship\": \"Container S.\"\n",
    "}\n",
    "\n",
    "# === Folder to save ===\n",
    "fig_dir = r\"C:\\Users\\30697\\Documents\\MSc in ISFM\\5th_Bimester_Thesis\\Thesis\\Figures\"\n",
    "\n",
    "# === Variables to plot (x, xlabel, title) ===\n",
    "plot_vars = [\n",
    "    (\"TEI\", \"TEI [gCO₂ / t·nm]\", \"CO₂ Eff. vs TEI\"),\n",
    "    (\"Speed\", \"Speed [knots]\", \"CO₂ Eff. vs Speed\"),\n",
    "    (\"Age\", \"Age [years]\", \"CO₂ Eff. vs Age\"),\n",
    "    (\"DWT\", \"DWT [t]\", \"CO₂ Eff. vs DWT\")\n",
    "]\n",
    "\n",
    "# === Create 2×2 subplot ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(13, 9))\n",
    "fig.suptitle(\"Relationships Between CO₂ Efficiency and Explanatory Variables\",\n",
    "             fontsize=18, fontweight=\"bold\", y=0.95, x=0.5)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# === Plot each variable ===\n",
    "for ax, (x_var, x_label, title) in zip(axes, plot_vars):\n",
    "    for ship in ship_order:\n",
    "        if ship not in panel_df[\"Ship_type\"].unique():\n",
    "            continue\n",
    "        # Subsample data to 30% for lighter plots\n",
    "        subset = panel_df[panel_df[\"Ship_type\"] == ship].sample(frac=0.75, random_state=1) #in case there are too many keep a fraction\n",
    "        \n",
    "        # Scatter (rasterized for small file size)\n",
    "        sns.scatterplot(\n",
    "            data=subset,\n",
    "            x=x_var, y=\"CO2_Eff\",\n",
    "            color=color_map[ship], alpha=0.25, s=25, ax=ax,\n",
    "            rasterized=True  # 🔹 rasterize scatter points\n",
    "        )\n",
    "\n",
    "        # Smoothed regression trend (kept vector)\n",
    "        sns.regplot(\n",
    "            data=subset,\n",
    "            x=x_var, y=\"CO2_Eff\",\n",
    "            scatter=False, ci=None,\n",
    "            color=color_map[ship], ax=ax\n",
    "        )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label, labelpad=3)\n",
    "    ax.set_ylabel(\"CO₂ Efficiency [gCO₂ / t·nm]\", labelpad=3)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# === Create one common legend (centered on top) ===\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=color_map[ship], lw=2, label=legend_labels[ship])\n",
    "    for ship in ship_order\n",
    "]\n",
    "leg = fig.legend(\n",
    "    handles=legend_elements,\n",
    "    title=\"Ship Type\", title_fontsize=14, fontsize=13,\n",
    "    loc=\"upper center\", ncol=4,\n",
    "    bbox_to_anchor=(0.51, 0.0225), frameon=True\n",
    ")\n",
    "plt.setp(leg.get_title(), fontweight=\"bold\")\n",
    "\n",
    "# === Adjust layout and save ===\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96], h_pad=2, w_pad=2)\n",
    "\n",
    "save_path = os.path.join(fig_dir, \"CO2_vs_All_Independent_Variables_2.svg\")\n",
    "plt.savefig(save_path, format=\"svg\", bbox_inches=\"tight\")  # ✅ vector + raster mix\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Figure saved successfully at:\\n{save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
